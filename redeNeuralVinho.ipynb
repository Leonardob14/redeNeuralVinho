{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of atividadeVinho.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leonardob14/redeNeuralVinho/blob/master/redeNeuralVinho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA1FKb0CC2BG",
        "colab_type": "text"
      },
      "source": [
        "### Exemplo de MLP com TensorFlow em Notebook\n",
        "\n",
        "Primeiramente, **importar** o dataset para o Drive  e  os pacotes necess√°rios.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8IiDDErp43W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27-Pyov6Fry-",
        "colab_type": "code",
        "outputId": "22a67a49-f28c-4913-956b-5b9a5514c741",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e6e9f3a9-3c67-4154-9c19-486f2e436ebf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e6e9f3a9-3c67-4154-9c19-486f2e436ebf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving titanic_train.csv to titanic_train.csv\n",
            "User uploaded file \"titanic_train.csv\" with length 61194 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpQPkTUTDtF4",
        "colab_type": "text"
      },
      "source": [
        "Gerando Seed Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoJQzDOiDuxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_miFSbBDz2Y",
        "colab_type": "text"
      },
      "source": [
        "Carregando o **dataset** e ajustando as matrizes X  e Y (Labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0R-b9g9D4hE",
        "colab_type": "code",
        "outputId": "cb6283c3-238b-418f-97bd-9efbb0196df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "dataset = np.loadtxt(\"titanic_train.csv\", delimiter=\",\")\n",
        "\n",
        "# Separando colunas input (X) e output (Y) \n",
        "X = dataset[:,0:11]\n",
        "Y = dataset[:,11]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-21e395b25592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"titanic_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Separando colunas input (X) e output (Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'0x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'PassengerId'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jvbE4PWt9Ln",
        "colab_type": "code",
        "outputId": "21818245-4583-4c7f-93b6-9851ce9809b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(Y[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb3G6jvCEERu",
        "colab_type": "text"
      },
      "source": [
        "Criando modelo MLP com 3 camadas (64 - 32 - 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Yc6qLnEHXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "inputs = keras.Input(shape=(11,)) \n",
        "x = keras.layers.Dense(256, activation='relu')(inputs)\n",
        "x = keras.layers.Dense(128, activation='relu')(x)\n",
        "x = keras.layers.Dense(64, activation='relu')(x)\n",
        "x = keras.layers.Dense(32, activation='relu')(x)\n",
        "x = keras.layers.Dense(16, activation='relu')(x)\n",
        "predictions = keras.layers.Dense(11, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs,outputs=predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7J4aG7gGFSPm",
        "outputId": "30cc41ba-8dce-48ae-d9c3-2bcb2a79d1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1599/1599 [==============================] - 0s 107us/sample - loss: 5.8159 - acc: 0.0338\n",
            "acc: 3.38%\n",
            "Train on 1599 samples, validate on 1599 samples\n",
            "Epoch 1/1000\n",
            "1599/1599 [==============================] - 0s 125us/sample - loss: 3.5142 - acc: 0.2308 - val_loss: 2.1866 - val_acc: 0.4071\n",
            "Epoch 2/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.9584 - acc: 0.4115 - val_loss: 1.7779 - val_acc: 0.3709\n",
            "Epoch 3/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.6869 - acc: 0.4303 - val_loss: 1.6064 - val_acc: 0.4472\n",
            "Epoch 4/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.5411 - acc: 0.4734 - val_loss: 1.4449 - val_acc: 0.4765\n",
            "Epoch 5/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.4416 - acc: 0.4522 - val_loss: 1.3533 - val_acc: 0.4759\n",
            "Epoch 6/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.3453 - acc: 0.4803 - val_loss: 1.2979 - val_acc: 0.5022\n",
            "Epoch 7/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.2920 - acc: 0.4941 - val_loss: 1.2910 - val_acc: 0.4878\n",
            "Epoch 8/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.2826 - acc: 0.4897 - val_loss: 1.2240 - val_acc: 0.4991\n",
            "Epoch 9/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.2384 - acc: 0.4953 - val_loss: 1.2194 - val_acc: 0.4991\n",
            "Epoch 10/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.2197 - acc: 0.4941 - val_loss: 1.2250 - val_acc: 0.4972\n",
            "Epoch 11/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.2222 - acc: 0.5028 - val_loss: 1.2031 - val_acc: 0.5028\n",
            "Epoch 12/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.2039 - acc: 0.5034 - val_loss: 1.1972 - val_acc: 0.5247\n",
            "Epoch 13/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.1883 - acc: 0.5022 - val_loss: 1.2033 - val_acc: 0.4997\n",
            "Epoch 14/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.2113 - acc: 0.4984 - val_loss: 1.1951 - val_acc: 0.4834\n",
            "Epoch 15/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.2029 - acc: 0.4991 - val_loss: 1.2097 - val_acc: 0.4991\n",
            "Epoch 16/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.2064 - acc: 0.4866 - val_loss: 1.1823 - val_acc: 0.5141\n",
            "Epoch 17/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.1878 - acc: 0.5097 - val_loss: 1.1688 - val_acc: 0.5109\n",
            "Epoch 18/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.1830 - acc: 0.4984 - val_loss: 1.2012 - val_acc: 0.4734\n",
            "Epoch 19/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.1814 - acc: 0.5034 - val_loss: 1.1798 - val_acc: 0.5266\n",
            "Epoch 20/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.1594 - acc: 0.5059 - val_loss: 1.1564 - val_acc: 0.5147\n",
            "Epoch 21/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.1621 - acc: 0.5116 - val_loss: 1.1494 - val_acc: 0.5241\n",
            "Epoch 22/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.1625 - acc: 0.5128 - val_loss: 1.1839 - val_acc: 0.4834\n",
            "Epoch 23/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.1678 - acc: 0.4922 - val_loss: 1.1540 - val_acc: 0.5247\n",
            "Epoch 24/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.1568 - acc: 0.5009 - val_loss: 1.1558 - val_acc: 0.5303\n",
            "Epoch 25/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 1.1652 - acc: 0.5253 - val_loss: 1.1347 - val_acc: 0.5084\n",
            "Epoch 26/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.1368 - acc: 0.5091 - val_loss: 1.1511 - val_acc: 0.5084\n",
            "Epoch 27/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.1431 - acc: 0.5241 - val_loss: 1.1354 - val_acc: 0.5053\n",
            "Epoch 28/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.1306 - acc: 0.5103 - val_loss: 1.1178 - val_acc: 0.5228\n",
            "Epoch 29/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 1.1195 - acc: 0.5303 - val_loss: 1.1185 - val_acc: 0.5253\n",
            "Epoch 30/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.1392 - acc: 0.5203 - val_loss: 1.1075 - val_acc: 0.5316\n",
            "Epoch 31/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 1.1271 - acc: 0.5260 - val_loss: 1.1191 - val_acc: 0.5172\n",
            "Epoch 32/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.1277 - acc: 0.5210 - val_loss: 1.1340 - val_acc: 0.5072\n",
            "Epoch 33/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.1316 - acc: 0.5072 - val_loss: 1.1270 - val_acc: 0.5016\n",
            "Epoch 34/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.1179 - acc: 0.5084 - val_loss: 1.1321 - val_acc: 0.4947\n",
            "Epoch 35/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.1263 - acc: 0.5003 - val_loss: 1.1080 - val_acc: 0.5153\n",
            "Epoch 36/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.1184 - acc: 0.5222 - val_loss: 1.1035 - val_acc: 0.5184\n",
            "Epoch 37/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.1107 - acc: 0.5022 - val_loss: 1.1016 - val_acc: 0.5109\n",
            "Epoch 38/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.1069 - acc: 0.5178 - val_loss: 1.1004 - val_acc: 0.5253\n",
            "Epoch 39/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.1056 - acc: 0.5166 - val_loss: 1.0994 - val_acc: 0.5084\n",
            "Epoch 40/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.1143 - acc: 0.5191 - val_loss: 1.0975 - val_acc: 0.5322\n",
            "Epoch 41/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 1.1003 - acc: 0.5241 - val_loss: 1.1033 - val_acc: 0.5210\n",
            "Epoch 42/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.1081 - acc: 0.5147 - val_loss: 1.0842 - val_acc: 0.5216\n",
            "Epoch 43/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0883 - acc: 0.5241 - val_loss: 1.0916 - val_acc: 0.5122\n",
            "Epoch 44/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.1039 - acc: 0.5084 - val_loss: 1.1052 - val_acc: 0.5172\n",
            "Epoch 45/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.1037 - acc: 0.5122 - val_loss: 1.0870 - val_acc: 0.5191\n",
            "Epoch 46/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0955 - acc: 0.5084 - val_loss: 1.0766 - val_acc: 0.5253\n",
            "Epoch 47/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0910 - acc: 0.5072 - val_loss: 1.0834 - val_acc: 0.5285\n",
            "Epoch 48/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0843 - acc: 0.5372 - val_loss: 1.0772 - val_acc: 0.5397\n",
            "Epoch 49/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0838 - acc: 0.5266 - val_loss: 1.0792 - val_acc: 0.5235\n",
            "Epoch 50/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0879 - acc: 0.5247 - val_loss: 1.0694 - val_acc: 0.5516\n",
            "Epoch 51/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.0810 - acc: 0.5460 - val_loss: 1.0632 - val_acc: 0.5485\n",
            "Epoch 52/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0862 - acc: 0.5253 - val_loss: 1.0715 - val_acc: 0.5422\n",
            "Epoch 53/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.0795 - acc: 0.5410 - val_loss: 1.0994 - val_acc: 0.5241\n",
            "Epoch 54/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0924 - acc: 0.5378 - val_loss: 1.0728 - val_acc: 0.5410\n",
            "Epoch 55/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0780 - acc: 0.5447 - val_loss: 1.0779 - val_acc: 0.5472\n",
            "Epoch 56/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.0918 - acc: 0.5328 - val_loss: 1.1138 - val_acc: 0.5228\n",
            "Epoch 57/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.1091 - acc: 0.5272 - val_loss: 1.0754 - val_acc: 0.5403\n",
            "Epoch 58/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 1.0940 - acc: 0.5184 - val_loss: 1.0603 - val_acc: 0.5403\n",
            "Epoch 59/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0759 - acc: 0.5397 - val_loss: 1.0592 - val_acc: 0.5503\n",
            "Epoch 60/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.0598 - acc: 0.5397 - val_loss: 1.0891 - val_acc: 0.5310\n",
            "Epoch 61/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0955 - acc: 0.5266 - val_loss: 1.0668 - val_acc: 0.5372\n",
            "Epoch 62/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 1.0851 - acc: 0.5266 - val_loss: 1.0655 - val_acc: 0.5353\n",
            "Epoch 63/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0681 - acc: 0.5347 - val_loss: 1.0513 - val_acc: 0.5391\n",
            "Epoch 64/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.0538 - acc: 0.5466 - val_loss: 1.0517 - val_acc: 0.5328\n",
            "Epoch 65/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0555 - acc: 0.5441 - val_loss: 1.0447 - val_acc: 0.5528\n",
            "Epoch 66/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0564 - acc: 0.5441 - val_loss: 1.0643 - val_acc: 0.5416\n",
            "Epoch 67/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0697 - acc: 0.5403 - val_loss: 1.0447 - val_acc: 0.5522\n",
            "Epoch 68/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0486 - acc: 0.5353 - val_loss: 1.0460 - val_acc: 0.5485\n",
            "Epoch 69/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.0558 - acc: 0.5428 - val_loss: 1.0450 - val_acc: 0.5366\n",
            "Epoch 70/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 1.0460 - acc: 0.5447 - val_loss: 1.0548 - val_acc: 0.5447\n",
            "Epoch 71/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0443 - acc: 0.5460 - val_loss: 1.0436 - val_acc: 0.5441\n",
            "Epoch 72/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0435 - acc: 0.5466 - val_loss: 1.0249 - val_acc: 0.5578\n",
            "Epoch 73/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0289 - acc: 0.5547 - val_loss: 1.0243 - val_acc: 0.5647\n",
            "Epoch 74/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0384 - acc: 0.5585 - val_loss: 1.0267 - val_acc: 0.5597\n",
            "Epoch 75/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0411 - acc: 0.5541 - val_loss: 1.0226 - val_acc: 0.5672\n",
            "Epoch 76/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 1.0325 - acc: 0.5553 - val_loss: 1.0346 - val_acc: 0.5366\n",
            "Epoch 77/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0359 - acc: 0.5572 - val_loss: 1.0260 - val_acc: 0.5497\n",
            "Epoch 78/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 1.0265 - acc: 0.5447 - val_loss: 1.0424 - val_acc: 0.5478\n",
            "Epoch 79/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0397 - acc: 0.5335 - val_loss: 1.0247 - val_acc: 0.5660\n",
            "Epoch 80/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 1.0339 - acc: 0.5597 - val_loss: 1.0173 - val_acc: 0.5510\n",
            "Epoch 81/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.0293 - acc: 0.5547 - val_loss: 1.0138 - val_acc: 0.5541\n",
            "Epoch 82/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0244 - acc: 0.5541 - val_loss: 1.0232 - val_acc: 0.5553\n",
            "Epoch 83/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 1.0245 - acc: 0.5616 - val_loss: 1.0443 - val_acc: 0.5347\n",
            "Epoch 84/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0213 - acc: 0.5553 - val_loss: 1.0040 - val_acc: 0.5635\n",
            "Epoch 85/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0128 - acc: 0.5641 - val_loss: 0.9980 - val_acc: 0.5691\n",
            "Epoch 86/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 1.0027 - acc: 0.5760 - val_loss: 0.9978 - val_acc: 0.5591\n",
            "Epoch 87/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0054 - acc: 0.5604 - val_loss: 0.9899 - val_acc: 0.5747\n",
            "Epoch 88/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0098 - acc: 0.5622 - val_loss: 1.0044 - val_acc: 0.5647\n",
            "Epoch 89/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0051 - acc: 0.5697 - val_loss: 0.9895 - val_acc: 0.5816\n",
            "Epoch 90/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9985 - acc: 0.5729 - val_loss: 0.9908 - val_acc: 0.5616\n",
            "Epoch 91/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9942 - acc: 0.5729 - val_loss: 0.9828 - val_acc: 0.5710\n",
            "Epoch 92/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9890 - acc: 0.5704 - val_loss: 0.9959 - val_acc: 0.5629\n",
            "Epoch 93/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0084 - acc: 0.5485 - val_loss: 1.0039 - val_acc: 0.5516\n",
            "Epoch 94/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 1.0126 - acc: 0.5516 - val_loss: 1.0098 - val_acc: 0.5585\n",
            "Epoch 95/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0280 - acc: 0.5503 - val_loss: 1.0114 - val_acc: 0.5604\n",
            "Epoch 96/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0106 - acc: 0.5466 - val_loss: 0.9909 - val_acc: 0.5685\n",
            "Epoch 97/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 1.0107 - acc: 0.5528 - val_loss: 1.0143 - val_acc: 0.5497\n",
            "Epoch 98/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0050 - acc: 0.5610 - val_loss: 1.0356 - val_acc: 0.5666\n",
            "Epoch 99/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 1.0212 - acc: 0.5597 - val_loss: 0.9979 - val_acc: 0.5591\n",
            "Epoch 100/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 1.0047 - acc: 0.5528 - val_loss: 0.9948 - val_acc: 0.5766\n",
            "Epoch 101/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0047 - acc: 0.5597 - val_loss: 0.9761 - val_acc: 0.5785\n",
            "Epoch 102/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9885 - acc: 0.5622 - val_loss: 0.9661 - val_acc: 0.5829\n",
            "Epoch 103/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9850 - acc: 0.5785 - val_loss: 0.9624 - val_acc: 0.5829\n",
            "Epoch 104/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9806 - acc: 0.5716 - val_loss: 0.9714 - val_acc: 0.5772\n",
            "Epoch 105/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9807 - acc: 0.5722 - val_loss: 0.9706 - val_acc: 0.5804\n",
            "Epoch 106/1000\n",
            "1599/1599 [==============================] - 0s 37us/sample - loss: 0.9959 - acc: 0.5629 - val_loss: 0.9737 - val_acc: 0.5716\n",
            "Epoch 107/1000\n",
            "1599/1599 [==============================] - 0s 39us/sample - loss: 0.9840 - acc: 0.5697 - val_loss: 0.9705 - val_acc: 0.5791\n",
            "Epoch 108/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9768 - acc: 0.5666 - val_loss: 0.9806 - val_acc: 0.5660\n",
            "Epoch 109/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9734 - acc: 0.5697 - val_loss: 0.9725 - val_acc: 0.5822\n",
            "Epoch 110/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9689 - acc: 0.5722 - val_loss: 0.9692 - val_acc: 0.5629\n",
            "Epoch 111/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9802 - acc: 0.5722 - val_loss: 1.0144 - val_acc: 0.5597\n",
            "Epoch 112/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9769 - acc: 0.5754 - val_loss: 0.9804 - val_acc: 0.5710\n",
            "Epoch 113/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9785 - acc: 0.5541 - val_loss: 0.9962 - val_acc: 0.5591\n",
            "Epoch 114/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9880 - acc: 0.5553 - val_loss: 0.9996 - val_acc: 0.5666\n",
            "Epoch 115/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9862 - acc: 0.5578 - val_loss: 0.9989 - val_acc: 0.5541\n",
            "Epoch 116/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 1.0238 - acc: 0.5453 - val_loss: 0.9533 - val_acc: 0.5854\n",
            "Epoch 117/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9663 - acc: 0.5854 - val_loss: 0.9671 - val_acc: 0.5816\n",
            "Epoch 118/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9658 - acc: 0.5710 - val_loss: 0.9483 - val_acc: 0.5866\n",
            "Epoch 119/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9628 - acc: 0.5735 - val_loss: 0.9586 - val_acc: 0.5754\n",
            "Epoch 120/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9692 - acc: 0.5754 - val_loss: 0.9506 - val_acc: 0.5847\n",
            "Epoch 121/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9730 - acc: 0.5679 - val_loss: 0.9549 - val_acc: 0.5854\n",
            "Epoch 122/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9765 - acc: 0.5747 - val_loss: 0.9693 - val_acc: 0.5716\n",
            "Epoch 123/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9637 - acc: 0.5741 - val_loss: 0.9569 - val_acc: 0.5810\n",
            "Epoch 124/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9589 - acc: 0.5722 - val_loss: 0.9527 - val_acc: 0.5685\n",
            "Epoch 125/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9681 - acc: 0.5704 - val_loss: 0.9998 - val_acc: 0.5616\n",
            "Epoch 126/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9815 - acc: 0.5697 - val_loss: 0.9527 - val_acc: 0.5785\n",
            "Epoch 127/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9695 - acc: 0.5729 - val_loss: 0.9556 - val_acc: 0.5722\n",
            "Epoch 128/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9579 - acc: 0.5797 - val_loss: 0.9485 - val_acc: 0.5829\n",
            "Epoch 129/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.9548 - acc: 0.5791 - val_loss: 0.9519 - val_acc: 0.5791\n",
            "Epoch 130/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9546 - acc: 0.5722 - val_loss: 0.9527 - val_acc: 0.5791\n",
            "Epoch 131/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9587 - acc: 0.5772 - val_loss: 0.9483 - val_acc: 0.5866\n",
            "Epoch 132/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9472 - acc: 0.5860 - val_loss: 0.9456 - val_acc: 0.5804\n",
            "Epoch 133/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9488 - acc: 0.5847 - val_loss: 0.9470 - val_acc: 0.5760\n",
            "Epoch 134/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9474 - acc: 0.5866 - val_loss: 0.9596 - val_acc: 0.5704\n",
            "Epoch 135/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9566 - acc: 0.5722 - val_loss: 0.9311 - val_acc: 0.5979\n",
            "Epoch 136/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9555 - acc: 0.5879 - val_loss: 0.9639 - val_acc: 0.5691\n",
            "Epoch 137/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9868 - acc: 0.5591 - val_loss: 0.9667 - val_acc: 0.5710\n",
            "Epoch 138/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9932 - acc: 0.5547 - val_loss: 0.9874 - val_acc: 0.5722\n",
            "Epoch 139/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9720 - acc: 0.5666 - val_loss: 1.0073 - val_acc: 0.5491\n",
            "Epoch 140/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9568 - acc: 0.5635 - val_loss: 0.9448 - val_acc: 0.5866\n",
            "Epoch 141/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9511 - acc: 0.5772 - val_loss: 0.9276 - val_acc: 0.5854\n",
            "Epoch 142/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9319 - acc: 0.5885 - val_loss: 0.9368 - val_acc: 0.5954\n",
            "Epoch 143/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9362 - acc: 0.5947 - val_loss: 0.9253 - val_acc: 0.5847\n",
            "Epoch 144/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9251 - acc: 0.5822 - val_loss: 0.9368 - val_acc: 0.5847\n",
            "Epoch 145/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.9310 - acc: 0.5879 - val_loss: 0.9251 - val_acc: 0.5797\n",
            "Epoch 146/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9318 - acc: 0.5779 - val_loss: 0.9133 - val_acc: 0.5935\n",
            "Epoch 147/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9236 - acc: 0.6004 - val_loss: 0.9169 - val_acc: 0.6073\n",
            "Epoch 148/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9364 - acc: 0.6004 - val_loss: 0.9100 - val_acc: 0.6029\n",
            "Epoch 149/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9215 - acc: 0.5935 - val_loss: 0.9273 - val_acc: 0.5829\n",
            "Epoch 150/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9335 - acc: 0.5866 - val_loss: 0.9100 - val_acc: 0.6029\n",
            "Epoch 151/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9217 - acc: 0.5891 - val_loss: 0.9127 - val_acc: 0.5985\n",
            "Epoch 152/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9254 - acc: 0.5860 - val_loss: 0.9132 - val_acc: 0.6123\n",
            "Epoch 153/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9263 - acc: 0.5947 - val_loss: 0.9677 - val_acc: 0.5729\n",
            "Epoch 154/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9406 - acc: 0.5741 - val_loss: 0.9183 - val_acc: 0.5972\n",
            "Epoch 155/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9173 - acc: 0.5979 - val_loss: 0.9046 - val_acc: 0.5979\n",
            "Epoch 156/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9175 - acc: 0.5985 - val_loss: 0.9084 - val_acc: 0.6135\n",
            "Epoch 157/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.9297 - acc: 0.5954 - val_loss: 0.9169 - val_acc: 0.6048\n",
            "Epoch 158/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.9482 - acc: 0.5735 - val_loss: 0.9613 - val_acc: 0.5704\n",
            "Epoch 159/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.9357 - acc: 0.5954 - val_loss: 0.9116 - val_acc: 0.5985\n",
            "Epoch 160/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9161 - acc: 0.5885 - val_loss: 0.8980 - val_acc: 0.6079\n",
            "Epoch 161/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9108 - acc: 0.5985 - val_loss: 0.9093 - val_acc: 0.6091\n",
            "Epoch 162/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9263 - acc: 0.5872 - val_loss: 0.9075 - val_acc: 0.6066\n",
            "Epoch 163/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9040 - acc: 0.6066 - val_loss: 0.8938 - val_acc: 0.5991\n",
            "Epoch 164/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.9077 - acc: 0.5904 - val_loss: 0.9073 - val_acc: 0.6041\n",
            "Epoch 165/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9127 - acc: 0.5966 - val_loss: 0.8992 - val_acc: 0.6016\n",
            "Epoch 166/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9065 - acc: 0.5947 - val_loss: 0.8998 - val_acc: 0.5897\n",
            "Epoch 167/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9116 - acc: 0.5960 - val_loss: 0.8918 - val_acc: 0.6091\n",
            "Epoch 168/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9035 - acc: 0.5997 - val_loss: 0.8995 - val_acc: 0.6066\n",
            "Epoch 169/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9026 - acc: 0.5954 - val_loss: 0.9066 - val_acc: 0.5997\n",
            "Epoch 170/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9127 - acc: 0.5866 - val_loss: 0.8945 - val_acc: 0.6048\n",
            "Epoch 171/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9086 - acc: 0.5929 - val_loss: 0.9134 - val_acc: 0.6041\n",
            "Epoch 172/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9336 - acc: 0.5947 - val_loss: 0.8901 - val_acc: 0.6035\n",
            "Epoch 173/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.9372 - acc: 0.5847 - val_loss: 0.9100 - val_acc: 0.6085\n",
            "Epoch 174/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9110 - acc: 0.5979 - val_loss: 0.8915 - val_acc: 0.6079\n",
            "Epoch 175/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9083 - acc: 0.5954 - val_loss: 0.9141 - val_acc: 0.6004\n",
            "Epoch 176/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.9029 - acc: 0.5922 - val_loss: 0.8988 - val_acc: 0.6104\n",
            "Epoch 177/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9119 - acc: 0.5960 - val_loss: 0.9008 - val_acc: 0.5904\n",
            "Epoch 178/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8977 - acc: 0.6048 - val_loss: 0.9218 - val_acc: 0.5804\n",
            "Epoch 179/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.9202 - acc: 0.5991 - val_loss: 0.9137 - val_acc: 0.5822\n",
            "Epoch 180/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9188 - acc: 0.5947 - val_loss: 0.9050 - val_acc: 0.6066\n",
            "Epoch 181/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9267 - acc: 0.6010 - val_loss: 0.9049 - val_acc: 0.6085\n",
            "Epoch 182/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.9210 - acc: 0.5985 - val_loss: 0.9006 - val_acc: 0.6160\n",
            "Epoch 183/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9091 - acc: 0.6004 - val_loss: 0.8935 - val_acc: 0.6135\n",
            "Epoch 184/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.9001 - acc: 0.6048 - val_loss: 0.8877 - val_acc: 0.6116\n",
            "Epoch 185/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8989 - acc: 0.6048 - val_loss: 0.9043 - val_acc: 0.6191\n",
            "Epoch 186/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9113 - acc: 0.5910 - val_loss: 0.9226 - val_acc: 0.6023\n",
            "Epoch 187/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9076 - acc: 0.6098 - val_loss: 0.8941 - val_acc: 0.6166\n",
            "Epoch 188/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8992 - acc: 0.6048 - val_loss: 0.8893 - val_acc: 0.6010\n",
            "Epoch 189/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8944 - acc: 0.6066 - val_loss: 0.8796 - val_acc: 0.6210\n",
            "Epoch 190/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8868 - acc: 0.6079 - val_loss: 0.9285 - val_acc: 0.6054\n",
            "Epoch 191/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9014 - acc: 0.6173 - val_loss: 0.8989 - val_acc: 0.6104\n",
            "Epoch 192/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8942 - acc: 0.5979 - val_loss: 0.8743 - val_acc: 0.6254\n",
            "Epoch 193/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8807 - acc: 0.6154 - val_loss: 0.8833 - val_acc: 0.6266\n",
            "Epoch 194/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8859 - acc: 0.6235 - val_loss: 0.8710 - val_acc: 0.6154\n",
            "Epoch 195/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8801 - acc: 0.6135 - val_loss: 0.8689 - val_acc: 0.6116\n",
            "Epoch 196/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8780 - acc: 0.6041 - val_loss: 0.8680 - val_acc: 0.6141\n",
            "Epoch 197/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8848 - acc: 0.6073 - val_loss: 0.8712 - val_acc: 0.6204\n",
            "Epoch 198/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8956 - acc: 0.6004 - val_loss: 0.9547 - val_acc: 0.5810\n",
            "Epoch 199/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9511 - acc: 0.5754 - val_loss: 0.9448 - val_acc: 0.5847\n",
            "Epoch 200/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.9348 - acc: 0.5697 - val_loss: 0.8831 - val_acc: 0.6104\n",
            "Epoch 201/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.9093 - acc: 0.5979 - val_loss: 0.8924 - val_acc: 0.5972\n",
            "Epoch 202/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.9199 - acc: 0.5866 - val_loss: 0.8951 - val_acc: 0.6116\n",
            "Epoch 203/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.9056 - acc: 0.5979 - val_loss: 0.8949 - val_acc: 0.6135\n",
            "Epoch 204/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8969 - acc: 0.6004 - val_loss: 0.8699 - val_acc: 0.6266\n",
            "Epoch 205/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8780 - acc: 0.6123 - val_loss: 0.8831 - val_acc: 0.6085\n",
            "Epoch 206/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8800 - acc: 0.6185 - val_loss: 0.8594 - val_acc: 0.6198\n",
            "Epoch 207/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8703 - acc: 0.6204 - val_loss: 0.8730 - val_acc: 0.6173\n",
            "Epoch 208/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8790 - acc: 0.6116 - val_loss: 0.8721 - val_acc: 0.6204\n",
            "Epoch 209/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8761 - acc: 0.6148 - val_loss: 0.8541 - val_acc: 0.6285\n",
            "Epoch 210/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8670 - acc: 0.6229 - val_loss: 0.8569 - val_acc: 0.6241\n",
            "Epoch 211/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.8638 - acc: 0.6279 - val_loss: 0.8643 - val_acc: 0.6260\n",
            "Epoch 212/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8726 - acc: 0.6198 - val_loss: 0.8583 - val_acc: 0.6204\n",
            "Epoch 213/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8683 - acc: 0.6148 - val_loss: 0.8678 - val_acc: 0.6198\n",
            "Epoch 214/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8950 - acc: 0.5954 - val_loss: 0.8999 - val_acc: 0.6048\n",
            "Epoch 215/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.9129 - acc: 0.5966 - val_loss: 0.8778 - val_acc: 0.6198\n",
            "Epoch 216/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8926 - acc: 0.6048 - val_loss: 0.8648 - val_acc: 0.6229\n",
            "Epoch 217/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.8852 - acc: 0.6141 - val_loss: 0.8918 - val_acc: 0.5960\n",
            "Epoch 218/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8855 - acc: 0.6166 - val_loss: 0.8905 - val_acc: 0.6004\n",
            "Epoch 219/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8820 - acc: 0.6141 - val_loss: 0.8550 - val_acc: 0.6160\n",
            "Epoch 220/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8652 - acc: 0.6091 - val_loss: 0.9143 - val_acc: 0.5910\n",
            "Epoch 221/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8845 - acc: 0.6129 - val_loss: 0.8746 - val_acc: 0.6091\n",
            "Epoch 222/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8814 - acc: 0.6048 - val_loss: 0.8520 - val_acc: 0.6260\n",
            "Epoch 223/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8836 - acc: 0.6229 - val_loss: 0.9002 - val_acc: 0.6110\n",
            "Epoch 224/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8858 - acc: 0.6116 - val_loss: 0.8556 - val_acc: 0.6304\n",
            "Epoch 225/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8608 - acc: 0.6241 - val_loss: 0.8487 - val_acc: 0.6279\n",
            "Epoch 226/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8643 - acc: 0.6160 - val_loss: 0.8598 - val_acc: 0.6260\n",
            "Epoch 227/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.8573 - acc: 0.6291 - val_loss: 0.8419 - val_acc: 0.6335\n",
            "Epoch 228/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8684 - acc: 0.6154 - val_loss: 0.8540 - val_acc: 0.6279\n",
            "Epoch 229/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8673 - acc: 0.6254 - val_loss: 0.8488 - val_acc: 0.6379\n",
            "Epoch 230/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8642 - acc: 0.6223 - val_loss: 0.8486 - val_acc: 0.6279\n",
            "Epoch 231/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8579 - acc: 0.6273 - val_loss: 0.8549 - val_acc: 0.6091\n",
            "Epoch 232/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.8484 - acc: 0.6316 - val_loss: 0.8401 - val_acc: 0.6266\n",
            "Epoch 233/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8522 - acc: 0.6204 - val_loss: 0.8412 - val_acc: 0.6273\n",
            "Epoch 234/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8505 - acc: 0.6191 - val_loss: 0.8353 - val_acc: 0.6254\n",
            "Epoch 235/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.8430 - acc: 0.6254 - val_loss: 0.8646 - val_acc: 0.6135\n",
            "Epoch 236/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8644 - acc: 0.6141 - val_loss: 0.8518 - val_acc: 0.6204\n",
            "Epoch 237/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8579 - acc: 0.6335 - val_loss: 0.8489 - val_acc: 0.6248\n",
            "Epoch 238/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8570 - acc: 0.6366 - val_loss: 0.8441 - val_acc: 0.6323\n",
            "Epoch 239/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8578 - acc: 0.6160 - val_loss: 0.8286 - val_acc: 0.6448\n",
            "Epoch 240/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8432 - acc: 0.6323 - val_loss: 0.8712 - val_acc: 0.6216\n",
            "Epoch 241/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8595 - acc: 0.6216 - val_loss: 0.8861 - val_acc: 0.6198\n",
            "Epoch 242/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8667 - acc: 0.6160 - val_loss: 0.8327 - val_acc: 0.6379\n",
            "Epoch 243/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8526 - acc: 0.6235 - val_loss: 0.8543 - val_acc: 0.6129\n",
            "Epoch 244/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8530 - acc: 0.6216 - val_loss: 0.8778 - val_acc: 0.5997\n",
            "Epoch 245/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8563 - acc: 0.6229 - val_loss: 0.8578 - val_acc: 0.6135\n",
            "Epoch 246/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8595 - acc: 0.6241 - val_loss: 0.8360 - val_acc: 0.6241\n",
            "Epoch 247/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8533 - acc: 0.6273 - val_loss: 0.8363 - val_acc: 0.6366\n",
            "Epoch 248/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8594 - acc: 0.6304 - val_loss: 0.8365 - val_acc: 0.6323\n",
            "Epoch 249/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8525 - acc: 0.6285 - val_loss: 0.8326 - val_acc: 0.6329\n",
            "Epoch 250/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8493 - acc: 0.6248 - val_loss: 0.8457 - val_acc: 0.6266\n",
            "Epoch 251/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8373 - acc: 0.6279 - val_loss: 0.8527 - val_acc: 0.6323\n",
            "Epoch 252/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8523 - acc: 0.6291 - val_loss: 0.8541 - val_acc: 0.6341\n",
            "Epoch 253/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8499 - acc: 0.6266 - val_loss: 0.8440 - val_acc: 0.6229\n",
            "Epoch 254/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.8628 - acc: 0.6229 - val_loss: 0.8535 - val_acc: 0.6116\n",
            "Epoch 255/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8650 - acc: 0.6173 - val_loss: 0.8253 - val_acc: 0.6404\n",
            "Epoch 256/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8282 - acc: 0.6329 - val_loss: 0.8542 - val_acc: 0.6198\n",
            "Epoch 257/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8592 - acc: 0.6266 - val_loss: 0.8949 - val_acc: 0.6010\n",
            "Epoch 258/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8568 - acc: 0.6291 - val_loss: 0.8225 - val_acc: 0.6454\n",
            "Epoch 259/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8425 - acc: 0.6260 - val_loss: 0.8480 - val_acc: 0.6341\n",
            "Epoch 260/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8473 - acc: 0.6316 - val_loss: 0.8429 - val_acc: 0.6404\n",
            "Epoch 261/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.8607 - acc: 0.6235 - val_loss: 0.8302 - val_acc: 0.6341\n",
            "Epoch 262/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8465 - acc: 0.6341 - val_loss: 0.8230 - val_acc: 0.6410\n",
            "Epoch 263/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8341 - acc: 0.6360 - val_loss: 0.8675 - val_acc: 0.6204\n",
            "Epoch 264/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8644 - acc: 0.6185 - val_loss: 0.8149 - val_acc: 0.6442\n",
            "Epoch 265/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8577 - acc: 0.6198 - val_loss: 0.8331 - val_acc: 0.6229\n",
            "Epoch 266/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8466 - acc: 0.6210 - val_loss: 0.8232 - val_acc: 0.6304\n",
            "Epoch 267/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8333 - acc: 0.6366 - val_loss: 0.8427 - val_acc: 0.6185\n",
            "Epoch 268/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8394 - acc: 0.6291 - val_loss: 0.8445 - val_acc: 0.6204\n",
            "Epoch 269/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8369 - acc: 0.6273 - val_loss: 0.8585 - val_acc: 0.6041\n",
            "Epoch 270/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8446 - acc: 0.6285 - val_loss: 0.8343 - val_acc: 0.6235\n",
            "Epoch 271/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.8294 - acc: 0.6354 - val_loss: 0.8317 - val_acc: 0.6241\n",
            "Epoch 272/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8315 - acc: 0.6404 - val_loss: 0.8130 - val_acc: 0.6423\n",
            "Epoch 273/1000\n",
            "1599/1599 [==============================] - 0s 38us/sample - loss: 0.8249 - acc: 0.6285 - val_loss: 0.8042 - val_acc: 0.6504\n",
            "Epoch 274/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8123 - acc: 0.6523 - val_loss: 0.8168 - val_acc: 0.6291\n",
            "Epoch 275/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8115 - acc: 0.6354 - val_loss: 0.8060 - val_acc: 0.6504\n",
            "Epoch 276/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8187 - acc: 0.6454 - val_loss: 0.8130 - val_acc: 0.6498\n",
            "Epoch 277/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8235 - acc: 0.6385 - val_loss: 0.7978 - val_acc: 0.6523\n",
            "Epoch 278/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8165 - acc: 0.6366 - val_loss: 0.8091 - val_acc: 0.6498\n",
            "Epoch 279/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8097 - acc: 0.6517 - val_loss: 0.8066 - val_acc: 0.6404\n",
            "Epoch 280/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8214 - acc: 0.6398 - val_loss: 0.8052 - val_acc: 0.6579\n",
            "Epoch 281/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8142 - acc: 0.6554 - val_loss: 0.8304 - val_acc: 0.6354\n",
            "Epoch 282/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8294 - acc: 0.6360 - val_loss: 0.8315 - val_acc: 0.6279\n",
            "Epoch 283/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8248 - acc: 0.6316 - val_loss: 0.8397 - val_acc: 0.6198\n",
            "Epoch 284/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8428 - acc: 0.6241 - val_loss: 0.8550 - val_acc: 0.6235\n",
            "Epoch 285/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8516 - acc: 0.6366 - val_loss: 0.8669 - val_acc: 0.6098\n",
            "Epoch 286/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8437 - acc: 0.6229 - val_loss: 0.8135 - val_acc: 0.6335\n",
            "Epoch 287/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8199 - acc: 0.6417 - val_loss: 0.8088 - val_acc: 0.6485\n",
            "Epoch 288/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8169 - acc: 0.6417 - val_loss: 0.8069 - val_acc: 0.6473\n",
            "Epoch 289/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8182 - acc: 0.6510 - val_loss: 0.8042 - val_acc: 0.6460\n",
            "Epoch 290/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8293 - acc: 0.6410 - val_loss: 0.8268 - val_acc: 0.6223\n",
            "Epoch 291/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8110 - acc: 0.6542 - val_loss: 0.8377 - val_acc: 0.6335\n",
            "Epoch 292/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8321 - acc: 0.6260 - val_loss: 0.8199 - val_acc: 0.6310\n",
            "Epoch 293/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8428 - acc: 0.6254 - val_loss: 0.8046 - val_acc: 0.6410\n",
            "Epoch 294/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.8281 - acc: 0.6442 - val_loss: 0.8070 - val_acc: 0.6510\n",
            "Epoch 295/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8238 - acc: 0.6329 - val_loss: 0.8015 - val_acc: 0.6485\n",
            "Epoch 296/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8122 - acc: 0.6385 - val_loss: 0.8255 - val_acc: 0.6485\n",
            "Epoch 297/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8223 - acc: 0.6429 - val_loss: 0.8154 - val_acc: 0.6417\n",
            "Epoch 298/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8381 - acc: 0.6360 - val_loss: 0.8126 - val_acc: 0.6442\n",
            "Epoch 299/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8291 - acc: 0.6260 - val_loss: 0.8126 - val_acc: 0.6423\n",
            "Epoch 300/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8135 - acc: 0.6573 - val_loss: 0.7928 - val_acc: 0.6492\n",
            "Epoch 301/1000\n",
            "1599/1599 [==============================] - 0s 40us/sample - loss: 0.7981 - acc: 0.6498 - val_loss: 0.7934 - val_acc: 0.6604\n",
            "Epoch 302/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.7949 - acc: 0.6567 - val_loss: 0.7795 - val_acc: 0.6635\n",
            "Epoch 303/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7881 - acc: 0.6592 - val_loss: 0.7779 - val_acc: 0.6635\n",
            "Epoch 304/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7898 - acc: 0.6604 - val_loss: 0.7799 - val_acc: 0.6648\n",
            "Epoch 305/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7833 - acc: 0.6610 - val_loss: 0.8166 - val_acc: 0.6291\n",
            "Epoch 306/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8003 - acc: 0.6373 - val_loss: 0.8244 - val_acc: 0.6229\n",
            "Epoch 307/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8188 - acc: 0.6298 - val_loss: 0.7877 - val_acc: 0.6585\n",
            "Epoch 308/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8219 - acc: 0.6492 - val_loss: 0.7833 - val_acc: 0.6523\n",
            "Epoch 309/1000\n",
            "1599/1599 [==============================] - 0s 38us/sample - loss: 0.8027 - acc: 0.6479 - val_loss: 0.7902 - val_acc: 0.6510\n",
            "Epoch 310/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8252 - acc: 0.6379 - val_loss: 0.7863 - val_acc: 0.6592\n",
            "Epoch 311/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8007 - acc: 0.6548 - val_loss: 0.8063 - val_acc: 0.6429\n",
            "Epoch 312/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8044 - acc: 0.6485 - val_loss: 0.8174 - val_acc: 0.6366\n",
            "Epoch 313/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8301 - acc: 0.6360 - val_loss: 0.8433 - val_acc: 0.6235\n",
            "Epoch 314/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8282 - acc: 0.6385 - val_loss: 0.7890 - val_acc: 0.6535\n",
            "Epoch 315/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.8071 - acc: 0.6510 - val_loss: 0.8071 - val_acc: 0.6517\n",
            "Epoch 316/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8139 - acc: 0.6454 - val_loss: 0.7911 - val_acc: 0.6598\n",
            "Epoch 317/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7981 - acc: 0.6592 - val_loss: 0.8003 - val_acc: 0.6635\n",
            "Epoch 318/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7999 - acc: 0.6448 - val_loss: 0.8072 - val_acc: 0.6523\n",
            "Epoch 319/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7962 - acc: 0.6548 - val_loss: 0.7979 - val_acc: 0.6560\n",
            "Epoch 320/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.7992 - acc: 0.6529 - val_loss: 0.7781 - val_acc: 0.6560\n",
            "Epoch 321/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7934 - acc: 0.6585 - val_loss: 0.7847 - val_acc: 0.6642\n",
            "Epoch 322/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7962 - acc: 0.6529 - val_loss: 0.7723 - val_acc: 0.6685\n",
            "Epoch 323/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7841 - acc: 0.6598 - val_loss: 0.7930 - val_acc: 0.6429\n",
            "Epoch 324/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7870 - acc: 0.6548 - val_loss: 0.7757 - val_acc: 0.6598\n",
            "Epoch 325/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7805 - acc: 0.6629 - val_loss: 0.7819 - val_acc: 0.6492\n",
            "Epoch 326/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7974 - acc: 0.6485 - val_loss: 0.7983 - val_acc: 0.6410\n",
            "Epoch 327/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7875 - acc: 0.6498 - val_loss: 0.7784 - val_acc: 0.6592\n",
            "Epoch 328/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7939 - acc: 0.6592 - val_loss: 0.7765 - val_acc: 0.6723\n",
            "Epoch 329/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8011 - acc: 0.6423 - val_loss: 0.7770 - val_acc: 0.6685\n",
            "Epoch 330/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.8116 - acc: 0.6429 - val_loss: 0.7966 - val_acc: 0.6610\n",
            "Epoch 331/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7972 - acc: 0.6610 - val_loss: 0.7702 - val_acc: 0.6629\n",
            "Epoch 332/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7834 - acc: 0.6529 - val_loss: 0.7704 - val_acc: 0.6560\n",
            "Epoch 333/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7904 - acc: 0.6585 - val_loss: 0.7775 - val_acc: 0.6435\n",
            "Epoch 334/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7820 - acc: 0.6498 - val_loss: 0.7726 - val_acc: 0.6623\n",
            "Epoch 335/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7956 - acc: 0.6467 - val_loss: 0.7833 - val_acc: 0.6592\n",
            "Epoch 336/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7964 - acc: 0.6629 - val_loss: 0.7930 - val_acc: 0.6610\n",
            "Epoch 337/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8044 - acc: 0.6485 - val_loss: 0.7906 - val_acc: 0.6642\n",
            "Epoch 338/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8100 - acc: 0.6510 - val_loss: 0.8333 - val_acc: 0.6229\n",
            "Epoch 339/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8264 - acc: 0.6316 - val_loss: 0.8199 - val_acc: 0.6492\n",
            "Epoch 340/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.8047 - acc: 0.6517 - val_loss: 0.7730 - val_acc: 0.6585\n",
            "Epoch 341/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7942 - acc: 0.6517 - val_loss: 0.7709 - val_acc: 0.6748\n",
            "Epoch 342/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7752 - acc: 0.6642 - val_loss: 0.7721 - val_acc: 0.6692\n",
            "Epoch 343/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7681 - acc: 0.6723 - val_loss: 0.7558 - val_acc: 0.6817\n",
            "Epoch 344/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7640 - acc: 0.6660 - val_loss: 0.7522 - val_acc: 0.6798\n",
            "Epoch 345/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7634 - acc: 0.6648 - val_loss: 0.7513 - val_acc: 0.6704\n",
            "Epoch 346/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.7730 - acc: 0.6610 - val_loss: 0.7777 - val_acc: 0.6385\n",
            "Epoch 347/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7658 - acc: 0.6573 - val_loss: 0.7593 - val_acc: 0.6654\n",
            "Epoch 348/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7711 - acc: 0.6629 - val_loss: 0.7706 - val_acc: 0.6542\n",
            "Epoch 349/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7721 - acc: 0.6629 - val_loss: 0.7619 - val_acc: 0.6748\n",
            "Epoch 350/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7751 - acc: 0.6548 - val_loss: 0.8204 - val_acc: 0.6410\n",
            "Epoch 351/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7932 - acc: 0.6473 - val_loss: 0.7451 - val_acc: 0.6685\n",
            "Epoch 352/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7662 - acc: 0.6560 - val_loss: 0.7581 - val_acc: 0.6735\n",
            "Epoch 353/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7579 - acc: 0.6754 - val_loss: 0.7515 - val_acc: 0.6773\n",
            "Epoch 354/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7773 - acc: 0.6535 - val_loss: 0.7960 - val_acc: 0.6567\n",
            "Epoch 355/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7895 - acc: 0.6623 - val_loss: 0.7655 - val_acc: 0.6748\n",
            "Epoch 356/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7735 - acc: 0.6629 - val_loss: 0.7618 - val_acc: 0.6635\n",
            "Epoch 357/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7839 - acc: 0.6504 - val_loss: 0.7747 - val_acc: 0.6554\n",
            "Epoch 358/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7603 - acc: 0.6648 - val_loss: 0.7576 - val_acc: 0.6629\n",
            "Epoch 359/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7577 - acc: 0.6529 - val_loss: 0.7533 - val_acc: 0.6648\n",
            "Epoch 360/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7622 - acc: 0.6710 - val_loss: 0.7598 - val_acc: 0.6748\n",
            "Epoch 361/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7827 - acc: 0.6635 - val_loss: 0.7626 - val_acc: 0.6798\n",
            "Epoch 362/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7647 - acc: 0.6685 - val_loss: 0.7449 - val_acc: 0.6560\n",
            "Epoch 363/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7716 - acc: 0.6592 - val_loss: 0.9147 - val_acc: 0.5941\n",
            "Epoch 364/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.8710 - acc: 0.6160 - val_loss: 0.8892 - val_acc: 0.6085\n",
            "Epoch 365/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8382 - acc: 0.6279 - val_loss: 0.8281 - val_acc: 0.6341\n",
            "Epoch 366/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7989 - acc: 0.6473 - val_loss: 0.7802 - val_acc: 0.6460\n",
            "Epoch 367/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.7832 - acc: 0.6642 - val_loss: 0.7592 - val_acc: 0.6692\n",
            "Epoch 368/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7620 - acc: 0.6742 - val_loss: 0.7619 - val_acc: 0.6667\n",
            "Epoch 369/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7693 - acc: 0.6579 - val_loss: 0.7569 - val_acc: 0.6717\n",
            "Epoch 370/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7738 - acc: 0.6673 - val_loss: 0.7505 - val_acc: 0.6836\n",
            "Epoch 371/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7691 - acc: 0.6692 - val_loss: 0.7588 - val_acc: 0.6779\n",
            "Epoch 372/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7579 - acc: 0.6673 - val_loss: 0.7479 - val_acc: 0.6629\n",
            "Epoch 373/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7532 - acc: 0.6673 - val_loss: 0.7378 - val_acc: 0.6773\n",
            "Epoch 374/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7471 - acc: 0.6685 - val_loss: 0.7741 - val_acc: 0.6573\n",
            "Epoch 375/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7621 - acc: 0.6598 - val_loss: 0.7795 - val_acc: 0.6429\n",
            "Epoch 376/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7648 - acc: 0.6717 - val_loss: 0.7374 - val_acc: 0.6754\n",
            "Epoch 377/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7443 - acc: 0.6798 - val_loss: 0.7312 - val_acc: 0.6811\n",
            "Epoch 378/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7461 - acc: 0.6710 - val_loss: 0.7434 - val_acc: 0.6723\n",
            "Epoch 379/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7506 - acc: 0.6604 - val_loss: 0.7430 - val_acc: 0.6754\n",
            "Epoch 380/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7477 - acc: 0.6861 - val_loss: 0.7625 - val_acc: 0.6529\n",
            "Epoch 381/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.7685 - acc: 0.6573 - val_loss: 0.7521 - val_acc: 0.6660\n",
            "Epoch 382/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7540 - acc: 0.6692 - val_loss: 0.7424 - val_acc: 0.6717\n",
            "Epoch 383/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7604 - acc: 0.6604 - val_loss: 0.7361 - val_acc: 0.6635\n",
            "Epoch 384/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7665 - acc: 0.6554 - val_loss: 0.8100 - val_acc: 0.6573\n",
            "Epoch 385/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7822 - acc: 0.6560 - val_loss: 0.7759 - val_acc: 0.6617\n",
            "Epoch 386/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7588 - acc: 0.6729 - val_loss: 0.7375 - val_acc: 0.6942\n",
            "Epoch 387/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7397 - acc: 0.6773 - val_loss: 0.7199 - val_acc: 0.6817\n",
            "Epoch 388/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7258 - acc: 0.6698 - val_loss: 0.7312 - val_acc: 0.6861\n",
            "Epoch 389/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7518 - acc: 0.6692 - val_loss: 0.7551 - val_acc: 0.6760\n",
            "Epoch 390/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7339 - acc: 0.6798 - val_loss: 0.7525 - val_acc: 0.6773\n",
            "Epoch 391/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7450 - acc: 0.6698 - val_loss: 0.7444 - val_acc: 0.6785\n",
            "Epoch 392/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7595 - acc: 0.6698 - val_loss: 0.7311 - val_acc: 0.6760\n",
            "Epoch 393/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7536 - acc: 0.6754 - val_loss: 0.7429 - val_acc: 0.6735\n",
            "Epoch 394/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7618 - acc: 0.6679 - val_loss: 0.7229 - val_acc: 0.6767\n",
            "Epoch 395/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7360 - acc: 0.6773 - val_loss: 0.7217 - val_acc: 0.6948\n",
            "Epoch 396/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7283 - acc: 0.6848 - val_loss: 0.7246 - val_acc: 0.6817\n",
            "Epoch 397/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7305 - acc: 0.6842 - val_loss: 0.7186 - val_acc: 0.6873\n",
            "Epoch 398/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7236 - acc: 0.6754 - val_loss: 0.7068 - val_acc: 0.6923\n",
            "Epoch 399/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.7302 - acc: 0.6717 - val_loss: 0.7190 - val_acc: 0.6992\n",
            "Epoch 400/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7428 - acc: 0.6767 - val_loss: 0.7274 - val_acc: 0.6823\n",
            "Epoch 401/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7357 - acc: 0.6735 - val_loss: 0.7217 - val_acc: 0.6823\n",
            "Epoch 402/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7345 - acc: 0.6698 - val_loss: 0.7113 - val_acc: 0.6779\n",
            "Epoch 403/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7279 - acc: 0.6798 - val_loss: 0.7185 - val_acc: 0.6923\n",
            "Epoch 404/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7328 - acc: 0.6760 - val_loss: 0.7186 - val_acc: 0.6848\n",
            "Epoch 405/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.7351 - acc: 0.6811 - val_loss: 0.7870 - val_acc: 0.6373\n",
            "Epoch 406/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7526 - acc: 0.6623 - val_loss: 0.7182 - val_acc: 0.6904\n",
            "Epoch 407/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7635 - acc: 0.6542 - val_loss: 0.7224 - val_acc: 0.6792\n",
            "Epoch 408/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7364 - acc: 0.6842 - val_loss: 0.7578 - val_acc: 0.6804\n",
            "Epoch 409/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7483 - acc: 0.6798 - val_loss: 0.7514 - val_acc: 0.6679\n",
            "Epoch 410/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7563 - acc: 0.6579 - val_loss: 0.7255 - val_acc: 0.6904\n",
            "Epoch 411/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7414 - acc: 0.6698 - val_loss: 0.7125 - val_acc: 0.6873\n",
            "Epoch 412/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7604 - acc: 0.6679 - val_loss: 0.7537 - val_acc: 0.6623\n",
            "Epoch 413/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7489 - acc: 0.6742 - val_loss: 0.8202 - val_acc: 0.6366\n",
            "Epoch 414/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7798 - acc: 0.6592 - val_loss: 0.7765 - val_acc: 0.6567\n",
            "Epoch 415/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.8008 - acc: 0.6467 - val_loss: 0.7468 - val_acc: 0.6510\n",
            "Epoch 416/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7701 - acc: 0.6567 - val_loss: 0.7438 - val_acc: 0.6642\n",
            "Epoch 417/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7457 - acc: 0.6754 - val_loss: 0.7320 - val_acc: 0.6867\n",
            "Epoch 418/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7365 - acc: 0.6773 - val_loss: 0.7425 - val_acc: 0.6654\n",
            "Epoch 419/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7300 - acc: 0.6717 - val_loss: 0.7288 - val_acc: 0.6842\n",
            "Epoch 420/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7204 - acc: 0.6836 - val_loss: 0.7080 - val_acc: 0.6779\n",
            "Epoch 421/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.7203 - acc: 0.6911 - val_loss: 0.7220 - val_acc: 0.6836\n",
            "Epoch 422/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.7318 - acc: 0.6829 - val_loss: 0.7037 - val_acc: 0.6917\n",
            "Epoch 423/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7156 - acc: 0.6873 - val_loss: 0.7199 - val_acc: 0.6879\n",
            "Epoch 424/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7244 - acc: 0.6823 - val_loss: 0.7301 - val_acc: 0.6717\n",
            "Epoch 425/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7142 - acc: 0.6929 - val_loss: 0.7005 - val_acc: 0.6942\n",
            "Epoch 426/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.6981 - acc: 0.6898 - val_loss: 0.6991 - val_acc: 0.6923\n",
            "Epoch 427/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7095 - acc: 0.6923 - val_loss: 0.7367 - val_acc: 0.6804\n",
            "Epoch 428/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7369 - acc: 0.6917 - val_loss: 0.6882 - val_acc: 0.7011\n",
            "Epoch 429/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7072 - acc: 0.6836 - val_loss: 0.6930 - val_acc: 0.7042\n",
            "Epoch 430/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7053 - acc: 0.6992 - val_loss: 0.7245 - val_acc: 0.6842\n",
            "Epoch 431/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7327 - acc: 0.6817 - val_loss: 0.7000 - val_acc: 0.6961\n",
            "Epoch 432/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.7220 - acc: 0.6861 - val_loss: 0.7643 - val_acc: 0.6760\n",
            "Epoch 433/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7516 - acc: 0.6717 - val_loss: 0.7577 - val_acc: 0.6642\n",
            "Epoch 434/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7265 - acc: 0.6742 - val_loss: 0.6906 - val_acc: 0.6886\n",
            "Epoch 435/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7110 - acc: 0.6754 - val_loss: 0.6812 - val_acc: 0.7004\n",
            "Epoch 436/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7045 - acc: 0.6942 - val_loss: 0.6959 - val_acc: 0.6898\n",
            "Epoch 437/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6987 - acc: 0.6954 - val_loss: 0.6798 - val_acc: 0.7042\n",
            "Epoch 438/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6955 - acc: 0.7004 - val_loss: 0.6783 - val_acc: 0.7079\n",
            "Epoch 439/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7043 - acc: 0.6842 - val_loss: 0.6961 - val_acc: 0.6998\n",
            "Epoch 440/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.7101 - acc: 0.6929 - val_loss: 0.7043 - val_acc: 0.7061\n",
            "Epoch 441/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6993 - acc: 0.6979 - val_loss: 0.6780 - val_acc: 0.7086\n",
            "Epoch 442/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6853 - acc: 0.7098 - val_loss: 0.6762 - val_acc: 0.7061\n",
            "Epoch 443/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.6836 - acc: 0.6986 - val_loss: 0.6758 - val_acc: 0.7148\n",
            "Epoch 444/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6946 - acc: 0.6948 - val_loss: 0.7010 - val_acc: 0.6986\n",
            "Epoch 445/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.7079 - acc: 0.6961 - val_loss: 0.7093 - val_acc: 0.6973\n",
            "Epoch 446/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6984 - acc: 0.6961 - val_loss: 0.7054 - val_acc: 0.7029\n",
            "Epoch 447/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7010 - acc: 0.6998 - val_loss: 0.6751 - val_acc: 0.7061\n",
            "Epoch 448/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.6899 - acc: 0.6992 - val_loss: 0.6776 - val_acc: 0.6936\n",
            "Epoch 449/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6888 - acc: 0.6967 - val_loss: 0.6924 - val_acc: 0.6936\n",
            "Epoch 450/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7064 - acc: 0.6917 - val_loss: 0.6712 - val_acc: 0.6992\n",
            "Epoch 451/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7261 - acc: 0.6854 - val_loss: 0.6911 - val_acc: 0.7011\n",
            "Epoch 452/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.6990 - acc: 0.6929 - val_loss: 0.7269 - val_acc: 0.6804\n",
            "Epoch 453/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7176 - acc: 0.6817 - val_loss: 0.6926 - val_acc: 0.6973\n",
            "Epoch 454/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7063 - acc: 0.6892 - val_loss: 0.6743 - val_acc: 0.7104\n",
            "Epoch 455/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6897 - acc: 0.7067 - val_loss: 0.6887 - val_acc: 0.7011\n",
            "Epoch 456/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6973 - acc: 0.6986 - val_loss: 0.6800 - val_acc: 0.7048\n",
            "Epoch 457/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.6930 - acc: 0.6923 - val_loss: 0.6996 - val_acc: 0.6854\n",
            "Epoch 458/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7061 - acc: 0.6986 - val_loss: 0.6727 - val_acc: 0.7073\n",
            "Epoch 459/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.7044 - acc: 0.6898 - val_loss: 0.7113 - val_acc: 0.6992\n",
            "Epoch 460/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7045 - acc: 0.7023 - val_loss: 0.6886 - val_acc: 0.7054\n",
            "Epoch 461/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.6930 - acc: 0.6961 - val_loss: 0.6829 - val_acc: 0.6873\n",
            "Epoch 462/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.6940 - acc: 0.6867 - val_loss: 0.6691 - val_acc: 0.7067\n",
            "Epoch 463/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6968 - acc: 0.6948 - val_loss: 0.7004 - val_acc: 0.6854\n",
            "Epoch 464/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.7005 - acc: 0.6917 - val_loss: 0.6725 - val_acc: 0.7111\n",
            "Epoch 465/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6864 - acc: 0.7029 - val_loss: 0.6716 - val_acc: 0.7148\n",
            "Epoch 466/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6780 - acc: 0.7092 - val_loss: 0.6696 - val_acc: 0.7123\n",
            "Epoch 467/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.6762 - acc: 0.7092 - val_loss: 0.6932 - val_acc: 0.6886\n",
            "Epoch 468/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7077 - acc: 0.6873 - val_loss: 0.6656 - val_acc: 0.7086\n",
            "Epoch 469/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6876 - acc: 0.7067 - val_loss: 0.6706 - val_acc: 0.7054\n",
            "Epoch 470/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6976 - acc: 0.6898 - val_loss: 0.6659 - val_acc: 0.7242\n",
            "Epoch 471/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6753 - acc: 0.7111 - val_loss: 0.6847 - val_acc: 0.7023\n",
            "Epoch 472/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6927 - acc: 0.6954 - val_loss: 0.6848 - val_acc: 0.6867\n",
            "Epoch 473/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.6902 - acc: 0.6911 - val_loss: 0.6970 - val_acc: 0.6811\n",
            "Epoch 474/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6912 - acc: 0.6998 - val_loss: 0.6649 - val_acc: 0.7054\n",
            "Epoch 475/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6690 - acc: 0.7061 - val_loss: 0.6561 - val_acc: 0.7142\n",
            "Epoch 476/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6840 - acc: 0.6961 - val_loss: 0.6566 - val_acc: 0.7198\n",
            "Epoch 477/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6849 - acc: 0.7011 - val_loss: 0.6667 - val_acc: 0.7067\n",
            "Epoch 478/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6706 - acc: 0.6979 - val_loss: 0.6650 - val_acc: 0.7036\n",
            "Epoch 479/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6817 - acc: 0.6979 - val_loss: 0.6605 - val_acc: 0.7142\n",
            "Epoch 480/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6845 - acc: 0.6954 - val_loss: 0.6617 - val_acc: 0.7098\n",
            "Epoch 481/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6738 - acc: 0.7036 - val_loss: 0.6846 - val_acc: 0.6929\n",
            "Epoch 482/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6824 - acc: 0.6917 - val_loss: 0.6624 - val_acc: 0.7111\n",
            "Epoch 483/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6696 - acc: 0.7042 - val_loss: 0.6623 - val_acc: 0.7073\n",
            "Epoch 484/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6689 - acc: 0.7061 - val_loss: 0.6579 - val_acc: 0.7198\n",
            "Epoch 485/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6692 - acc: 0.7042 - val_loss: 0.6668 - val_acc: 0.7029\n",
            "Epoch 486/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6798 - acc: 0.6954 - val_loss: 0.6576 - val_acc: 0.7179\n",
            "Epoch 487/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6642 - acc: 0.7148 - val_loss: 0.6551 - val_acc: 0.7305\n",
            "Epoch 488/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6682 - acc: 0.7123 - val_loss: 0.6414 - val_acc: 0.7255\n",
            "Epoch 489/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6584 - acc: 0.7136 - val_loss: 0.6428 - val_acc: 0.7173\n",
            "Epoch 490/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6612 - acc: 0.7023 - val_loss: 0.6406 - val_acc: 0.7186\n",
            "Epoch 491/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6682 - acc: 0.7048 - val_loss: 0.6414 - val_acc: 0.7129\n",
            "Epoch 492/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6598 - acc: 0.7117 - val_loss: 0.6418 - val_acc: 0.7179\n",
            "Epoch 493/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6660 - acc: 0.7054 - val_loss: 0.6460 - val_acc: 0.7192\n",
            "Epoch 494/1000\n",
            "1599/1599 [==============================] - 0s 39us/sample - loss: 0.6559 - acc: 0.7098 - val_loss: 0.6628 - val_acc: 0.7136\n",
            "Epoch 495/1000\n",
            "1599/1599 [==============================] - 0s 38us/sample - loss: 0.6561 - acc: 0.7173 - val_loss: 0.7011 - val_acc: 0.6823\n",
            "Epoch 496/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6847 - acc: 0.6892 - val_loss: 0.6790 - val_acc: 0.6854\n",
            "Epoch 497/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6829 - acc: 0.6886 - val_loss: 0.6792 - val_acc: 0.7061\n",
            "Epoch 498/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.7074 - acc: 0.6867 - val_loss: 0.7853 - val_acc: 0.6460\n",
            "Epoch 499/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7638 - acc: 0.6710 - val_loss: 0.7232 - val_acc: 0.6735\n",
            "Epoch 500/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7668 - acc: 0.6610 - val_loss: 0.7223 - val_acc: 0.6817\n",
            "Epoch 501/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.7243 - acc: 0.6748 - val_loss: 0.6729 - val_acc: 0.7029\n",
            "Epoch 502/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6787 - acc: 0.7029 - val_loss: 0.6613 - val_acc: 0.6992\n",
            "Epoch 503/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6654 - acc: 0.7048 - val_loss: 0.6531 - val_acc: 0.7142\n",
            "Epoch 504/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6627 - acc: 0.7098 - val_loss: 0.6400 - val_acc: 0.7330\n",
            "Epoch 505/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6551 - acc: 0.7179 - val_loss: 0.6481 - val_acc: 0.7179\n",
            "Epoch 506/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6596 - acc: 0.7167 - val_loss: 0.6542 - val_acc: 0.7273\n",
            "Epoch 507/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6650 - acc: 0.7173 - val_loss: 0.6788 - val_acc: 0.7230\n",
            "Epoch 508/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6817 - acc: 0.7036 - val_loss: 0.6569 - val_acc: 0.7111\n",
            "Epoch 509/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6818 - acc: 0.6948 - val_loss: 0.6552 - val_acc: 0.7073\n",
            "Epoch 510/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.6755 - acc: 0.7029 - val_loss: 0.7262 - val_acc: 0.6673\n",
            "Epoch 511/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6826 - acc: 0.6967 - val_loss: 0.6848 - val_acc: 0.6998\n",
            "Epoch 512/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6905 - acc: 0.6986 - val_loss: 0.6558 - val_acc: 0.7136\n",
            "Epoch 513/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6744 - acc: 0.6973 - val_loss: 0.6882 - val_acc: 0.7048\n",
            "Epoch 514/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6634 - acc: 0.7029 - val_loss: 0.6512 - val_acc: 0.7230\n",
            "Epoch 515/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6798 - acc: 0.7079 - val_loss: 0.6484 - val_acc: 0.7154\n",
            "Epoch 516/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.6678 - acc: 0.7098 - val_loss: 0.6551 - val_acc: 0.7236\n",
            "Epoch 517/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6688 - acc: 0.7148 - val_loss: 0.6395 - val_acc: 0.7267\n",
            "Epoch 518/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6464 - acc: 0.7205 - val_loss: 0.6343 - val_acc: 0.7273\n",
            "Epoch 519/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6470 - acc: 0.7217 - val_loss: 0.6274 - val_acc: 0.7311\n",
            "Epoch 520/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6350 - acc: 0.7236 - val_loss: 0.6439 - val_acc: 0.7305\n",
            "Epoch 521/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6363 - acc: 0.7217 - val_loss: 0.6187 - val_acc: 0.7417\n",
            "Epoch 522/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6322 - acc: 0.7273 - val_loss: 0.6380 - val_acc: 0.7255\n",
            "Epoch 523/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.6480 - acc: 0.7129 - val_loss: 0.6443 - val_acc: 0.7054\n",
            "Epoch 524/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.6495 - acc: 0.7042 - val_loss: 0.6322 - val_acc: 0.7223\n",
            "Epoch 525/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6510 - acc: 0.7142 - val_loss: 0.6224 - val_acc: 0.7298\n",
            "Epoch 526/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6474 - acc: 0.7161 - val_loss: 0.6727 - val_acc: 0.7073\n",
            "Epoch 527/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6542 - acc: 0.7042 - val_loss: 0.6207 - val_acc: 0.7348\n",
            "Epoch 528/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6345 - acc: 0.7267 - val_loss: 0.6432 - val_acc: 0.7167\n",
            "Epoch 529/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6391 - acc: 0.7255 - val_loss: 0.6211 - val_acc: 0.7380\n",
            "Epoch 530/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6392 - acc: 0.7230 - val_loss: 0.6240 - val_acc: 0.7273\n",
            "Epoch 531/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.6390 - acc: 0.7167 - val_loss: 0.6164 - val_acc: 0.7286\n",
            "Epoch 532/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6300 - acc: 0.7223 - val_loss: 0.6238 - val_acc: 0.7273\n",
            "Epoch 533/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6292 - acc: 0.7305 - val_loss: 0.6310 - val_acc: 0.7286\n",
            "Epoch 534/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.6288 - acc: 0.7154 - val_loss: 0.6167 - val_acc: 0.7386\n",
            "Epoch 535/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6205 - acc: 0.7305 - val_loss: 0.6089 - val_acc: 0.7373\n",
            "Epoch 536/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6415 - acc: 0.7148 - val_loss: 0.6044 - val_acc: 0.7505\n",
            "Epoch 537/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6347 - acc: 0.7261 - val_loss: 0.6179 - val_acc: 0.7230\n",
            "Epoch 538/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6381 - acc: 0.7154 - val_loss: 0.6193 - val_acc: 0.7273\n",
            "Epoch 539/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6438 - acc: 0.7223 - val_loss: 0.6449 - val_acc: 0.7267\n",
            "Epoch 540/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.6356 - acc: 0.7117 - val_loss: 0.6297 - val_acc: 0.7317\n",
            "Epoch 541/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6305 - acc: 0.7273 - val_loss: 0.5993 - val_acc: 0.7448\n",
            "Epoch 542/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6353 - acc: 0.7242 - val_loss: 0.6384 - val_acc: 0.7154\n",
            "Epoch 543/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6456 - acc: 0.7192 - val_loss: 0.5942 - val_acc: 0.7405\n",
            "Epoch 544/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.6324 - acc: 0.7223 - val_loss: 0.6552 - val_acc: 0.7192\n",
            "Epoch 545/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6521 - acc: 0.7267 - val_loss: 0.6175 - val_acc: 0.7380\n",
            "Epoch 546/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6376 - acc: 0.7223 - val_loss: 0.6176 - val_acc: 0.7311\n",
            "Epoch 547/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6467 - acc: 0.7205 - val_loss: 0.6460 - val_acc: 0.7192\n",
            "Epoch 548/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6403 - acc: 0.7211 - val_loss: 0.6126 - val_acc: 0.7330\n",
            "Epoch 549/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6338 - acc: 0.7242 - val_loss: 0.6409 - val_acc: 0.7230\n",
            "Epoch 550/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6613 - acc: 0.7111 - val_loss: 0.6579 - val_acc: 0.7242\n",
            "Epoch 551/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6476 - acc: 0.7167 - val_loss: 0.6411 - val_acc: 0.7317\n",
            "Epoch 552/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.6449 - acc: 0.7167 - val_loss: 0.5990 - val_acc: 0.7542\n",
            "Epoch 553/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6231 - acc: 0.7261 - val_loss: 0.6136 - val_acc: 0.7317\n",
            "Epoch 554/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6278 - acc: 0.7198 - val_loss: 0.6127 - val_acc: 0.7392\n",
            "Epoch 555/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6155 - acc: 0.7373 - val_loss: 0.5958 - val_acc: 0.7392\n",
            "Epoch 556/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6136 - acc: 0.7373 - val_loss: 0.5965 - val_acc: 0.7430\n",
            "Epoch 557/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6086 - acc: 0.7286 - val_loss: 0.5883 - val_acc: 0.7417\n",
            "Epoch 558/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6095 - acc: 0.7273 - val_loss: 0.5905 - val_acc: 0.7498\n",
            "Epoch 559/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6057 - acc: 0.7348 - val_loss: 0.6351 - val_acc: 0.7292\n",
            "Epoch 560/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6167 - acc: 0.7323 - val_loss: 0.5900 - val_acc: 0.7486\n",
            "Epoch 561/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5984 - acc: 0.7392 - val_loss: 0.5830 - val_acc: 0.7455\n",
            "Epoch 562/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5907 - acc: 0.7442 - val_loss: 0.5888 - val_acc: 0.7367\n",
            "Epoch 563/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5990 - acc: 0.7486 - val_loss: 0.5795 - val_acc: 0.7480\n",
            "Epoch 564/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.6018 - acc: 0.7411 - val_loss: 0.5955 - val_acc: 0.7386\n",
            "Epoch 565/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.6195 - acc: 0.7305 - val_loss: 0.6154 - val_acc: 0.7317\n",
            "Epoch 566/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6564 - acc: 0.7117 - val_loss: 0.6229 - val_acc: 0.7330\n",
            "Epoch 567/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6858 - acc: 0.7042 - val_loss: 0.7862 - val_acc: 0.6604\n",
            "Epoch 568/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.7086 - acc: 0.6861 - val_loss: 0.6963 - val_acc: 0.6929\n",
            "Epoch 569/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6595 - acc: 0.7073 - val_loss: 0.6514 - val_acc: 0.7023\n",
            "Epoch 570/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6557 - acc: 0.7148 - val_loss: 0.6324 - val_acc: 0.7167\n",
            "Epoch 571/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6508 - acc: 0.7104 - val_loss: 0.5969 - val_acc: 0.7342\n",
            "Epoch 572/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6553 - acc: 0.7211 - val_loss: 0.6765 - val_acc: 0.6992\n",
            "Epoch 573/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6496 - acc: 0.7198 - val_loss: 0.6285 - val_acc: 0.7348\n",
            "Epoch 574/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6317 - acc: 0.7286 - val_loss: 0.5919 - val_acc: 0.7442\n",
            "Epoch 575/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6209 - acc: 0.7348 - val_loss: 0.5992 - val_acc: 0.7455\n",
            "Epoch 576/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.6042 - acc: 0.7380 - val_loss: 0.5975 - val_acc: 0.7480\n",
            "Epoch 577/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6029 - acc: 0.7480 - val_loss: 0.5893 - val_acc: 0.7617\n",
            "Epoch 578/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5863 - acc: 0.7586 - val_loss: 0.5747 - val_acc: 0.7448\n",
            "Epoch 579/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5962 - acc: 0.7342 - val_loss: 0.5992 - val_acc: 0.7373\n",
            "Epoch 580/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6122 - acc: 0.7342 - val_loss: 0.5855 - val_acc: 0.7392\n",
            "Epoch 581/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.6043 - acc: 0.7298 - val_loss: 0.5988 - val_acc: 0.7367\n",
            "Epoch 582/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.6049 - acc: 0.7342 - val_loss: 0.6162 - val_acc: 0.7417\n",
            "Epoch 583/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.6214 - acc: 0.7317 - val_loss: 0.6072 - val_acc: 0.7355\n",
            "Epoch 584/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6095 - acc: 0.7411 - val_loss: 0.5882 - val_acc: 0.7498\n",
            "Epoch 585/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5972 - acc: 0.7398 - val_loss: 0.5910 - val_acc: 0.7323\n",
            "Epoch 586/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6049 - acc: 0.7355 - val_loss: 0.5766 - val_acc: 0.7467\n",
            "Epoch 587/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6208 - acc: 0.7248 - val_loss: 0.5816 - val_acc: 0.7605\n",
            "Epoch 588/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5915 - acc: 0.7430 - val_loss: 0.6065 - val_acc: 0.7517\n",
            "Epoch 589/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6108 - acc: 0.7361 - val_loss: 0.5847 - val_acc: 0.7436\n",
            "Epoch 590/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6359 - acc: 0.7217 - val_loss: 0.6253 - val_acc: 0.7267\n",
            "Epoch 591/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5941 - acc: 0.7473 - val_loss: 0.5732 - val_acc: 0.7530\n",
            "Epoch 592/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6001 - acc: 0.7348 - val_loss: 0.5897 - val_acc: 0.7523\n",
            "Epoch 593/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5871 - acc: 0.7486 - val_loss: 0.5757 - val_acc: 0.7536\n",
            "Epoch 594/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5711 - acc: 0.7542 - val_loss: 0.5820 - val_acc: 0.7598\n",
            "Epoch 595/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.5883 - acc: 0.7555 - val_loss: 0.5652 - val_acc: 0.7605\n",
            "Epoch 596/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5883 - acc: 0.7505 - val_loss: 0.5903 - val_acc: 0.7417\n",
            "Epoch 597/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5928 - acc: 0.7436 - val_loss: 0.5848 - val_acc: 0.7480\n",
            "Epoch 598/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5915 - acc: 0.7405 - val_loss: 0.5806 - val_acc: 0.7517\n",
            "Epoch 599/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6105 - acc: 0.7317 - val_loss: 0.6170 - val_acc: 0.7380\n",
            "Epoch 600/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.6355 - acc: 0.7173 - val_loss: 0.7556 - val_acc: 0.6710\n",
            "Epoch 601/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6677 - acc: 0.7054 - val_loss: 0.6140 - val_acc: 0.7348\n",
            "Epoch 602/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.6213 - acc: 0.7305 - val_loss: 0.6155 - val_acc: 0.7405\n",
            "Epoch 603/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6405 - acc: 0.7267 - val_loss: 0.5904 - val_acc: 0.7605\n",
            "Epoch 604/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6541 - acc: 0.7192 - val_loss: 0.5983 - val_acc: 0.7467\n",
            "Epoch 605/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.6107 - acc: 0.7467 - val_loss: 0.5846 - val_acc: 0.7586\n",
            "Epoch 606/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.6063 - acc: 0.7386 - val_loss: 0.5944 - val_acc: 0.7380\n",
            "Epoch 607/1000\n",
            "1599/1599 [==============================] - 0s 38us/sample - loss: 0.6066 - acc: 0.7298 - val_loss: 0.5888 - val_acc: 0.7461\n",
            "Epoch 608/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.6006 - acc: 0.7442 - val_loss: 0.5835 - val_acc: 0.7448\n",
            "Epoch 609/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5881 - acc: 0.7417 - val_loss: 0.6296 - val_acc: 0.7223\n",
            "Epoch 610/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5942 - acc: 0.7405 - val_loss: 0.5986 - val_acc: 0.7411\n",
            "Epoch 611/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5837 - acc: 0.7492 - val_loss: 0.6253 - val_acc: 0.7205\n",
            "Epoch 612/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5975 - acc: 0.7417 - val_loss: 0.5738 - val_acc: 0.7442\n",
            "Epoch 613/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5945 - acc: 0.7373 - val_loss: 0.5538 - val_acc: 0.7592\n",
            "Epoch 614/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5867 - acc: 0.7367 - val_loss: 0.5679 - val_acc: 0.7517\n",
            "Epoch 615/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.6006 - acc: 0.7323 - val_loss: 0.5882 - val_acc: 0.7492\n",
            "Epoch 616/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5867 - acc: 0.7505 - val_loss: 0.5816 - val_acc: 0.7517\n",
            "Epoch 617/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5902 - acc: 0.7386 - val_loss: 0.5818 - val_acc: 0.7592\n",
            "Epoch 618/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5820 - acc: 0.7461 - val_loss: 0.5801 - val_acc: 0.7473\n",
            "Epoch 619/1000\n",
            "1599/1599 [==============================] - 0s 37us/sample - loss: 0.5645 - acc: 0.7523 - val_loss: 0.5586 - val_acc: 0.7555\n",
            "Epoch 620/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5592 - acc: 0.7542 - val_loss: 0.5378 - val_acc: 0.7780\n",
            "Epoch 621/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5604 - acc: 0.7586 - val_loss: 0.5514 - val_acc: 0.7605\n",
            "Epoch 622/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5557 - acc: 0.7649 - val_loss: 0.5456 - val_acc: 0.7699\n",
            "Epoch 623/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5626 - acc: 0.7542 - val_loss: 0.5651 - val_acc: 0.7517\n",
            "Epoch 624/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5670 - acc: 0.7511 - val_loss: 0.5635 - val_acc: 0.7580\n",
            "Epoch 625/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5783 - acc: 0.7523 - val_loss: 0.5422 - val_acc: 0.7761\n",
            "Epoch 626/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5639 - acc: 0.7580 - val_loss: 0.5508 - val_acc: 0.7636\n",
            "Epoch 627/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5718 - acc: 0.7492 - val_loss: 0.5578 - val_acc: 0.7523\n",
            "Epoch 628/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5776 - acc: 0.7511 - val_loss: 0.5280 - val_acc: 0.7742\n",
            "Epoch 629/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5564 - acc: 0.7611 - val_loss: 0.5549 - val_acc: 0.7592\n",
            "Epoch 630/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5695 - acc: 0.7523 - val_loss: 0.5595 - val_acc: 0.7505\n",
            "Epoch 631/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5716 - acc: 0.7455 - val_loss: 0.5344 - val_acc: 0.7761\n",
            "Epoch 632/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5728 - acc: 0.7467 - val_loss: 0.5580 - val_acc: 0.7567\n",
            "Epoch 633/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5642 - acc: 0.7511 - val_loss: 0.5769 - val_acc: 0.7580\n",
            "Epoch 634/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5864 - acc: 0.7517 - val_loss: 0.5309 - val_acc: 0.7749\n",
            "Epoch 635/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5577 - acc: 0.7605 - val_loss: 0.5487 - val_acc: 0.7630\n",
            "Epoch 636/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5547 - acc: 0.7674 - val_loss: 0.5437 - val_acc: 0.7636\n",
            "Epoch 637/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5510 - acc: 0.7548 - val_loss: 0.5236 - val_acc: 0.7711\n",
            "Epoch 638/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5467 - acc: 0.7755 - val_loss: 0.5450 - val_acc: 0.7624\n",
            "Epoch 639/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5514 - acc: 0.7586 - val_loss: 0.5685 - val_acc: 0.7373\n",
            "Epoch 640/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5482 - acc: 0.7586 - val_loss: 0.5189 - val_acc: 0.7836\n",
            "Epoch 641/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5378 - acc: 0.7692 - val_loss: 0.5271 - val_acc: 0.7767\n",
            "Epoch 642/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5469 - acc: 0.7717 - val_loss: 0.5677 - val_acc: 0.7580\n",
            "Epoch 643/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5508 - acc: 0.7611 - val_loss: 0.5634 - val_acc: 0.7511\n",
            "Epoch 644/1000\n",
            "1599/1599 [==============================] - 0s 38us/sample - loss: 0.5602 - acc: 0.7467 - val_loss: 0.5497 - val_acc: 0.7530\n",
            "Epoch 645/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5563 - acc: 0.7542 - val_loss: 0.5214 - val_acc: 0.7792\n",
            "Epoch 646/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.5462 - acc: 0.7592 - val_loss: 0.5383 - val_acc: 0.7592\n",
            "Epoch 647/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.5323 - acc: 0.7630 - val_loss: 0.5412 - val_acc: 0.7498\n",
            "Epoch 648/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5370 - acc: 0.7661 - val_loss: 0.5466 - val_acc: 0.7511\n",
            "Epoch 649/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5421 - acc: 0.7617 - val_loss: 0.5568 - val_acc: 0.7642\n",
            "Epoch 650/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5547 - acc: 0.7642 - val_loss: 0.5253 - val_acc: 0.7692\n",
            "Epoch 651/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5389 - acc: 0.7705 - val_loss: 0.5342 - val_acc: 0.7711\n",
            "Epoch 652/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5432 - acc: 0.7624 - val_loss: 0.5258 - val_acc: 0.7817\n",
            "Epoch 653/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5324 - acc: 0.7680 - val_loss: 0.5230 - val_acc: 0.7805\n",
            "Epoch 654/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5307 - acc: 0.7724 - val_loss: 0.5156 - val_acc: 0.7792\n",
            "Epoch 655/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5443 - acc: 0.7686 - val_loss: 0.5374 - val_acc: 0.7624\n",
            "Epoch 656/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5459 - acc: 0.7649 - val_loss: 0.5209 - val_acc: 0.7705\n",
            "Epoch 657/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5471 - acc: 0.7686 - val_loss: 0.5222 - val_acc: 0.7692\n",
            "Epoch 658/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5332 - acc: 0.7736 - val_loss: 0.5089 - val_acc: 0.7849\n",
            "Epoch 659/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5619 - acc: 0.7548 - val_loss: 0.5906 - val_acc: 0.7311\n",
            "Epoch 660/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5869 - acc: 0.7442 - val_loss: 0.6019 - val_acc: 0.7186\n",
            "Epoch 661/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5792 - acc: 0.7386 - val_loss: 0.5606 - val_acc: 0.7511\n",
            "Epoch 662/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5637 - acc: 0.7523 - val_loss: 0.5199 - val_acc: 0.7805\n",
            "Epoch 663/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5361 - acc: 0.7786 - val_loss: 0.5147 - val_acc: 0.7792\n",
            "Epoch 664/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5470 - acc: 0.7717 - val_loss: 0.5034 - val_acc: 0.7767\n",
            "Epoch 665/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5398 - acc: 0.7655 - val_loss: 0.5328 - val_acc: 0.7774\n",
            "Epoch 666/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5369 - acc: 0.7724 - val_loss: 0.5257 - val_acc: 0.7699\n",
            "Epoch 667/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5366 - acc: 0.7630 - val_loss: 0.4979 - val_acc: 0.7911\n",
            "Epoch 668/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5504 - acc: 0.7667 - val_loss: 0.5230 - val_acc: 0.7799\n",
            "Epoch 669/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5634 - acc: 0.7580 - val_loss: 0.5287 - val_acc: 0.7730\n",
            "Epoch 670/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5704 - acc: 0.7542 - val_loss: 0.5343 - val_acc: 0.7680\n",
            "Epoch 671/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5619 - acc: 0.7536 - val_loss: 0.5507 - val_acc: 0.7636\n",
            "Epoch 672/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5384 - acc: 0.7736 - val_loss: 0.5349 - val_acc: 0.7674\n",
            "Epoch 673/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5628 - acc: 0.7536 - val_loss: 0.5644 - val_acc: 0.7473\n",
            "Epoch 674/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5735 - acc: 0.7486 - val_loss: 0.5265 - val_acc: 0.7811\n",
            "Epoch 675/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5726 - acc: 0.7548 - val_loss: 0.5457 - val_acc: 0.7655\n",
            "Epoch 676/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.5678 - acc: 0.7523 - val_loss: 0.5299 - val_acc: 0.7674\n",
            "Epoch 677/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5677 - acc: 0.7461 - val_loss: 0.5181 - val_acc: 0.7767\n",
            "Epoch 678/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5430 - acc: 0.7655 - val_loss: 0.5383 - val_acc: 0.7580\n",
            "Epoch 679/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5401 - acc: 0.7692 - val_loss: 0.5108 - val_acc: 0.7780\n",
            "Epoch 680/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5210 - acc: 0.7805 - val_loss: 0.5023 - val_acc: 0.7799\n",
            "Epoch 681/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5283 - acc: 0.7742 - val_loss: 0.5009 - val_acc: 0.7880\n",
            "Epoch 682/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5294 - acc: 0.7717 - val_loss: 0.5193 - val_acc: 0.7767\n",
            "Epoch 683/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5153 - acc: 0.7805 - val_loss: 0.5189 - val_acc: 0.7692\n",
            "Epoch 684/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5166 - acc: 0.7761 - val_loss: 0.4983 - val_acc: 0.7817\n",
            "Epoch 685/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5194 - acc: 0.7717 - val_loss: 0.4920 - val_acc: 0.7899\n",
            "Epoch 686/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5066 - acc: 0.7855 - val_loss: 0.4931 - val_acc: 0.7942\n",
            "Epoch 687/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5138 - acc: 0.7811 - val_loss: 0.4861 - val_acc: 0.7967\n",
            "Epoch 688/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.5030 - acc: 0.7892 - val_loss: 0.5222 - val_acc: 0.7686\n",
            "Epoch 689/1000\n",
            "1599/1599 [==============================] - 0s 37us/sample - loss: 0.5401 - acc: 0.7692 - val_loss: 0.5090 - val_acc: 0.7749\n",
            "Epoch 690/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5155 - acc: 0.7824 - val_loss: 0.4903 - val_acc: 0.7930\n",
            "Epoch 691/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5074 - acc: 0.7767 - val_loss: 0.4977 - val_acc: 0.7780\n",
            "Epoch 692/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5115 - acc: 0.7705 - val_loss: 0.5621 - val_acc: 0.7486\n",
            "Epoch 693/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5278 - acc: 0.7699 - val_loss: 0.4781 - val_acc: 0.8030\n",
            "Epoch 694/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5307 - acc: 0.7705 - val_loss: 0.5444 - val_acc: 0.7661\n",
            "Epoch 695/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5360 - acc: 0.7699 - val_loss: 0.5084 - val_acc: 0.7899\n",
            "Epoch 696/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5090 - acc: 0.7724 - val_loss: 0.4820 - val_acc: 0.7886\n",
            "Epoch 697/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4987 - acc: 0.7842 - val_loss: 0.4899 - val_acc: 0.7961\n",
            "Epoch 698/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5066 - acc: 0.7867 - val_loss: 0.5188 - val_acc: 0.7705\n",
            "Epoch 699/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5040 - acc: 0.7799 - val_loss: 0.4902 - val_acc: 0.7867\n",
            "Epoch 700/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4993 - acc: 0.7905 - val_loss: 0.4705 - val_acc: 0.8005\n",
            "Epoch 701/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4862 - acc: 0.7917 - val_loss: 0.4708 - val_acc: 0.7974\n",
            "Epoch 702/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4958 - acc: 0.7842 - val_loss: 0.4790 - val_acc: 0.7924\n",
            "Epoch 703/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5020 - acc: 0.7861 - val_loss: 0.4869 - val_acc: 0.7867\n",
            "Epoch 704/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4991 - acc: 0.7767 - val_loss: 0.5028 - val_acc: 0.7749\n",
            "Epoch 705/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5105 - acc: 0.7686 - val_loss: 0.4811 - val_acc: 0.7849\n",
            "Epoch 706/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4843 - acc: 0.7911 - val_loss: 0.4681 - val_acc: 0.7924\n",
            "Epoch 707/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4767 - acc: 0.7899 - val_loss: 0.4996 - val_acc: 0.7736\n",
            "Epoch 708/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4938 - acc: 0.7767 - val_loss: 0.4703 - val_acc: 0.8055\n",
            "Epoch 709/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4920 - acc: 0.7961 - val_loss: 0.4731 - val_acc: 0.7999\n",
            "Epoch 710/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.4877 - acc: 0.7936 - val_loss: 0.4942 - val_acc: 0.7949\n",
            "Epoch 711/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4924 - acc: 0.7905 - val_loss: 0.4800 - val_acc: 0.7917\n",
            "Epoch 712/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5072 - acc: 0.7761 - val_loss: 0.5014 - val_acc: 0.7905\n",
            "Epoch 713/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5251 - acc: 0.7736 - val_loss: 0.4752 - val_acc: 0.8111\n",
            "Epoch 714/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4892 - acc: 0.7980 - val_loss: 0.4913 - val_acc: 0.7942\n",
            "Epoch 715/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5124 - acc: 0.7830 - val_loss: 0.4752 - val_acc: 0.8024\n",
            "Epoch 716/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.5032 - acc: 0.7874 - val_loss: 0.4721 - val_acc: 0.7967\n",
            "Epoch 717/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4932 - acc: 0.7861 - val_loss: 0.4660 - val_acc: 0.8118\n",
            "Epoch 718/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4834 - acc: 0.8018 - val_loss: 0.4805 - val_acc: 0.7892\n",
            "Epoch 719/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4768 - acc: 0.7999 - val_loss: 0.4560 - val_acc: 0.8111\n",
            "Epoch 720/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4811 - acc: 0.7917 - val_loss: 0.4652 - val_acc: 0.8005\n",
            "Epoch 721/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4729 - acc: 0.7974 - val_loss: 0.4606 - val_acc: 0.8093\n",
            "Epoch 722/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4720 - acc: 0.8005 - val_loss: 0.4731 - val_acc: 0.7949\n",
            "Epoch 723/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4792 - acc: 0.8024 - val_loss: 0.4684 - val_acc: 0.7974\n",
            "Epoch 724/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4819 - acc: 0.7917 - val_loss: 0.4966 - val_acc: 0.7824\n",
            "Epoch 725/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4911 - acc: 0.7855 - val_loss: 0.4852 - val_acc: 0.7786\n",
            "Epoch 726/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5206 - acc: 0.7761 - val_loss: 0.4913 - val_acc: 0.7936\n",
            "Epoch 727/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5117 - acc: 0.7905 - val_loss: 0.5320 - val_acc: 0.7786\n",
            "Epoch 728/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5126 - acc: 0.7849 - val_loss: 0.5064 - val_acc: 0.7886\n",
            "Epoch 729/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4972 - acc: 0.7899 - val_loss: 0.4742 - val_acc: 0.8036\n",
            "Epoch 730/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5002 - acc: 0.7924 - val_loss: 0.4968 - val_acc: 0.7867\n",
            "Epoch 731/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4854 - acc: 0.7905 - val_loss: 0.5059 - val_acc: 0.7880\n",
            "Epoch 732/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4835 - acc: 0.7967 - val_loss: 0.4661 - val_acc: 0.8068\n",
            "Epoch 733/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4790 - acc: 0.7986 - val_loss: 0.4549 - val_acc: 0.8093\n",
            "Epoch 734/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4713 - acc: 0.8024 - val_loss: 0.4565 - val_acc: 0.8055\n",
            "Epoch 735/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4799 - acc: 0.7961 - val_loss: 0.4729 - val_acc: 0.7961\n",
            "Epoch 736/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4827 - acc: 0.7924 - val_loss: 0.4984 - val_acc: 0.7830\n",
            "Epoch 737/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4956 - acc: 0.7824 - val_loss: 0.4665 - val_acc: 0.8074\n",
            "Epoch 738/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4931 - acc: 0.7986 - val_loss: 0.4925 - val_acc: 0.7824\n",
            "Epoch 739/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4851 - acc: 0.7880 - val_loss: 0.5457 - val_acc: 0.7624\n",
            "Epoch 740/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5319 - acc: 0.7649 - val_loss: 0.5142 - val_acc: 0.7780\n",
            "Epoch 741/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5151 - acc: 0.7811 - val_loss: 0.4763 - val_acc: 0.7924\n",
            "Epoch 742/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4857 - acc: 0.7899 - val_loss: 0.4688 - val_acc: 0.7936\n",
            "Epoch 743/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4767 - acc: 0.7899 - val_loss: 0.4555 - val_acc: 0.8030\n",
            "Epoch 744/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4635 - acc: 0.7974 - val_loss: 0.4849 - val_acc: 0.7867\n",
            "Epoch 745/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4687 - acc: 0.7967 - val_loss: 0.4502 - val_acc: 0.8111\n",
            "Epoch 746/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4782 - acc: 0.7992 - val_loss: 0.4502 - val_acc: 0.8136\n",
            "Epoch 747/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4655 - acc: 0.8049 - val_loss: 0.4527 - val_acc: 0.7986\n",
            "Epoch 748/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4616 - acc: 0.8036 - val_loss: 0.4593 - val_acc: 0.8018\n",
            "Epoch 749/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.4703 - acc: 0.7917 - val_loss: 0.4583 - val_acc: 0.8061\n",
            "Epoch 750/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4736 - acc: 0.7980 - val_loss: 0.4837 - val_acc: 0.7867\n",
            "Epoch 751/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5014 - acc: 0.7842 - val_loss: 0.4661 - val_acc: 0.8030\n",
            "Epoch 752/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4879 - acc: 0.7974 - val_loss: 0.4612 - val_acc: 0.8111\n",
            "Epoch 753/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4643 - acc: 0.8005 - val_loss: 0.4621 - val_acc: 0.8061\n",
            "Epoch 754/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4715 - acc: 0.8036 - val_loss: 0.4670 - val_acc: 0.8049\n",
            "Epoch 755/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4823 - acc: 0.7936 - val_loss: 0.4690 - val_acc: 0.7955\n",
            "Epoch 756/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4698 - acc: 0.7942 - val_loss: 0.4451 - val_acc: 0.8093\n",
            "Epoch 757/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4637 - acc: 0.7974 - val_loss: 0.4412 - val_acc: 0.8068\n",
            "Epoch 758/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4536 - acc: 0.8068 - val_loss: 0.4541 - val_acc: 0.8030\n",
            "Epoch 759/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4483 - acc: 0.8174 - val_loss: 0.4519 - val_acc: 0.8155\n",
            "Epoch 760/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4553 - acc: 0.8061 - val_loss: 0.4327 - val_acc: 0.8186\n",
            "Epoch 761/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4503 - acc: 0.8093 - val_loss: 0.4304 - val_acc: 0.8224\n",
            "Epoch 762/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4487 - acc: 0.8111 - val_loss: 0.4845 - val_acc: 0.7874\n",
            "Epoch 763/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4949 - acc: 0.7786 - val_loss: 0.5037 - val_acc: 0.7892\n",
            "Epoch 764/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5234 - acc: 0.7792 - val_loss: 0.5755 - val_acc: 0.7630\n",
            "Epoch 765/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.5430 - acc: 0.7592 - val_loss: 0.4705 - val_acc: 0.7942\n",
            "Epoch 766/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5137 - acc: 0.7774 - val_loss: 0.4792 - val_acc: 0.7911\n",
            "Epoch 767/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5053 - acc: 0.7724 - val_loss: 0.4849 - val_acc: 0.7899\n",
            "Epoch 768/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4924 - acc: 0.7867 - val_loss: 0.4526 - val_acc: 0.8049\n",
            "Epoch 769/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5243 - acc: 0.7761 - val_loss: 0.5473 - val_acc: 0.7692\n",
            "Epoch 770/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5649 - acc: 0.7592 - val_loss: 0.6440 - val_acc: 0.7205\n",
            "Epoch 771/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5680 - acc: 0.7642 - val_loss: 0.5434 - val_acc: 0.7655\n",
            "Epoch 772/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.5406 - acc: 0.7717 - val_loss: 0.5140 - val_acc: 0.7780\n",
            "Epoch 773/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4991 - acc: 0.7911 - val_loss: 0.4657 - val_acc: 0.8111\n",
            "Epoch 774/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4817 - acc: 0.8030 - val_loss: 0.4611 - val_acc: 0.7949\n",
            "Epoch 775/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4802 - acc: 0.7917 - val_loss: 0.4504 - val_acc: 0.8118\n",
            "Epoch 776/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4741 - acc: 0.7986 - val_loss: 0.4521 - val_acc: 0.8011\n",
            "Epoch 777/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4782 - acc: 0.7949 - val_loss: 0.4459 - val_acc: 0.8261\n",
            "Epoch 778/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4774 - acc: 0.8049 - val_loss: 0.4774 - val_acc: 0.7949\n",
            "Epoch 779/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4686 - acc: 0.8011 - val_loss: 0.4543 - val_acc: 0.8011\n",
            "Epoch 780/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4590 - acc: 0.8111 - val_loss: 0.4363 - val_acc: 0.8149\n",
            "Epoch 781/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4505 - acc: 0.8118 - val_loss: 0.4528 - val_acc: 0.8036\n",
            "Epoch 782/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4583 - acc: 0.8018 - val_loss: 0.4248 - val_acc: 0.8243\n",
            "Epoch 783/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4373 - acc: 0.8168 - val_loss: 0.4196 - val_acc: 0.8305\n",
            "Epoch 784/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4325 - acc: 0.8161 - val_loss: 0.4381 - val_acc: 0.8155\n",
            "Epoch 785/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4427 - acc: 0.8143 - val_loss: 0.4374 - val_acc: 0.8149\n",
            "Epoch 786/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4518 - acc: 0.8099 - val_loss: 0.4343 - val_acc: 0.8186\n",
            "Epoch 787/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4773 - acc: 0.7911 - val_loss: 0.4330 - val_acc: 0.8274\n",
            "Epoch 788/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4488 - acc: 0.8124 - val_loss: 0.4214 - val_acc: 0.8299\n",
            "Epoch 789/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4480 - acc: 0.8199 - val_loss: 0.4410 - val_acc: 0.8143\n",
            "Epoch 790/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4501 - acc: 0.8136 - val_loss: 0.4804 - val_acc: 0.7899\n",
            "Epoch 791/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4537 - acc: 0.8130 - val_loss: 0.4411 - val_acc: 0.8168\n",
            "Epoch 792/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4628 - acc: 0.8011 - val_loss: 0.4498 - val_acc: 0.8124\n",
            "Epoch 793/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4748 - acc: 0.8049 - val_loss: 0.4390 - val_acc: 0.8205\n",
            "Epoch 794/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4723 - acc: 0.8055 - val_loss: 0.4409 - val_acc: 0.8143\n",
            "Epoch 795/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4598 - acc: 0.8049 - val_loss: 0.4490 - val_acc: 0.8043\n",
            "Epoch 796/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4517 - acc: 0.8043 - val_loss: 0.4248 - val_acc: 0.8243\n",
            "Epoch 797/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4341 - acc: 0.8161 - val_loss: 0.4326 - val_acc: 0.8230\n",
            "Epoch 798/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4406 - acc: 0.8186 - val_loss: 0.4111 - val_acc: 0.8305\n",
            "Epoch 799/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4416 - acc: 0.8268 - val_loss: 0.4408 - val_acc: 0.8243\n",
            "Epoch 800/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.4641 - acc: 0.8186 - val_loss: 0.5054 - val_acc: 0.7842\n",
            "Epoch 801/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4766 - acc: 0.7955 - val_loss: 0.4964 - val_acc: 0.7792\n",
            "Epoch 802/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4898 - acc: 0.7949 - val_loss: 0.4998 - val_acc: 0.7886\n",
            "Epoch 803/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5086 - acc: 0.7767 - val_loss: 0.4990 - val_acc: 0.7942\n",
            "Epoch 804/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.5082 - acc: 0.7936 - val_loss: 0.5362 - val_acc: 0.7874\n",
            "Epoch 805/1000\n",
            "1599/1599 [==============================] - 0s 28us/sample - loss: 0.5227 - acc: 0.7824 - val_loss: 0.5624 - val_acc: 0.7580\n",
            "Epoch 806/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.5099 - acc: 0.7824 - val_loss: 0.4750 - val_acc: 0.8068\n",
            "Epoch 807/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4745 - acc: 0.8024 - val_loss: 0.4534 - val_acc: 0.8030\n",
            "Epoch 808/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4474 - acc: 0.8099 - val_loss: 0.4580 - val_acc: 0.8049\n",
            "Epoch 809/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4618 - acc: 0.7980 - val_loss: 0.4602 - val_acc: 0.7980\n",
            "Epoch 810/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4494 - acc: 0.8111 - val_loss: 0.4389 - val_acc: 0.8093\n",
            "Epoch 811/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4600 - acc: 0.7986 - val_loss: 0.4801 - val_acc: 0.7992\n",
            "Epoch 812/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4714 - acc: 0.7980 - val_loss: 0.4534 - val_acc: 0.8155\n",
            "Epoch 813/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4660 - acc: 0.8080 - val_loss: 0.4571 - val_acc: 0.8111\n",
            "Epoch 814/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4621 - acc: 0.7961 - val_loss: 0.4286 - val_acc: 0.8255\n",
            "Epoch 815/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4320 - acc: 0.8149 - val_loss: 0.4348 - val_acc: 0.8099\n",
            "Epoch 816/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4394 - acc: 0.8124 - val_loss: 0.4297 - val_acc: 0.8161\n",
            "Epoch 817/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4238 - acc: 0.8224 - val_loss: 0.4429 - val_acc: 0.8105\n",
            "Epoch 818/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4318 - acc: 0.8180 - val_loss: 0.4283 - val_acc: 0.8230\n",
            "Epoch 819/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4321 - acc: 0.8124 - val_loss: 0.4228 - val_acc: 0.8161\n",
            "Epoch 820/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4391 - acc: 0.8130 - val_loss: 0.4500 - val_acc: 0.8005\n",
            "Epoch 821/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4479 - acc: 0.8005 - val_loss: 0.4297 - val_acc: 0.8199\n",
            "Epoch 822/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4365 - acc: 0.8218 - val_loss: 0.4331 - val_acc: 0.8149\n",
            "Epoch 823/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4463 - acc: 0.8074 - val_loss: 0.4472 - val_acc: 0.8080\n",
            "Epoch 824/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4475 - acc: 0.8168 - val_loss: 0.4219 - val_acc: 0.8155\n",
            "Epoch 825/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4342 - acc: 0.8111 - val_loss: 0.4043 - val_acc: 0.8305\n",
            "Epoch 826/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.4239 - acc: 0.8193 - val_loss: 0.4134 - val_acc: 0.8305\n",
            "Epoch 827/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4296 - acc: 0.8236 - val_loss: 0.4209 - val_acc: 0.8261\n",
            "Epoch 828/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4353 - acc: 0.8199 - val_loss: 0.4719 - val_acc: 0.7992\n",
            "Epoch 829/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4415 - acc: 0.8186 - val_loss: 0.4255 - val_acc: 0.8149\n",
            "Epoch 830/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4309 - acc: 0.8130 - val_loss: 0.4259 - val_acc: 0.8199\n",
            "Epoch 831/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4283 - acc: 0.8124 - val_loss: 0.3999 - val_acc: 0.8318\n",
            "Epoch 832/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4132 - acc: 0.8255 - val_loss: 0.4175 - val_acc: 0.8293\n",
            "Epoch 833/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4294 - acc: 0.8211 - val_loss: 0.4123 - val_acc: 0.8205\n",
            "Epoch 834/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4351 - acc: 0.8074 - val_loss: 0.4075 - val_acc: 0.8311\n",
            "Epoch 835/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4558 - acc: 0.8143 - val_loss: 0.4236 - val_acc: 0.8199\n",
            "Epoch 836/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4683 - acc: 0.8030 - val_loss: 0.4809 - val_acc: 0.7836\n",
            "Epoch 837/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4920 - acc: 0.7861 - val_loss: 0.4380 - val_acc: 0.8174\n",
            "Epoch 838/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.4522 - acc: 0.8036 - val_loss: 0.4243 - val_acc: 0.8136\n",
            "Epoch 839/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.4282 - acc: 0.8136 - val_loss: 0.4090 - val_acc: 0.8218\n",
            "Epoch 840/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4272 - acc: 0.8118 - val_loss: 0.4193 - val_acc: 0.8186\n",
            "Epoch 841/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4175 - acc: 0.8205 - val_loss: 0.4116 - val_acc: 0.8211\n",
            "Epoch 842/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3992 - acc: 0.8261 - val_loss: 0.3902 - val_acc: 0.8430\n",
            "Epoch 843/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4015 - acc: 0.8349 - val_loss: 0.3917 - val_acc: 0.8299\n",
            "Epoch 844/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.3998 - acc: 0.8324 - val_loss: 0.4074 - val_acc: 0.8118\n",
            "Epoch 845/1000\n",
            "1599/1599 [==============================] - 0s 29us/sample - loss: 0.4099 - acc: 0.8243 - val_loss: 0.3921 - val_acc: 0.8405\n",
            "Epoch 846/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4047 - acc: 0.8318 - val_loss: 0.4028 - val_acc: 0.8355\n",
            "Epoch 847/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4228 - acc: 0.8199 - val_loss: 0.4106 - val_acc: 0.8168\n",
            "Epoch 848/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.4225 - acc: 0.8080 - val_loss: 0.4012 - val_acc: 0.8311\n",
            "Epoch 849/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4176 - acc: 0.8243 - val_loss: 0.4213 - val_acc: 0.8218\n",
            "Epoch 850/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4380 - acc: 0.8155 - val_loss: 0.4079 - val_acc: 0.8274\n",
            "Epoch 851/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4372 - acc: 0.8174 - val_loss: 0.4234 - val_acc: 0.8224\n",
            "Epoch 852/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4443 - acc: 0.8243 - val_loss: 0.4112 - val_acc: 0.8236\n",
            "Epoch 853/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4243 - acc: 0.8230 - val_loss: 0.4201 - val_acc: 0.8261\n",
            "Epoch 854/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4363 - acc: 0.8155 - val_loss: 0.4658 - val_acc: 0.8043\n",
            "Epoch 855/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4425 - acc: 0.8099 - val_loss: 0.4370 - val_acc: 0.8074\n",
            "Epoch 856/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4305 - acc: 0.8130 - val_loss: 0.3992 - val_acc: 0.8386\n",
            "Epoch 857/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4069 - acc: 0.8236 - val_loss: 0.3949 - val_acc: 0.8343\n",
            "Epoch 858/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4151 - acc: 0.8236 - val_loss: 0.4105 - val_acc: 0.8330\n",
            "Epoch 859/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4097 - acc: 0.8311 - val_loss: 0.4007 - val_acc: 0.8361\n",
            "Epoch 860/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4013 - acc: 0.8299 - val_loss: 0.3892 - val_acc: 0.8318\n",
            "Epoch 861/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4055 - acc: 0.8280 - val_loss: 0.3884 - val_acc: 0.8374\n",
            "Epoch 862/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.4015 - acc: 0.8330 - val_loss: 0.3874 - val_acc: 0.8412\n",
            "Epoch 863/1000\n",
            "1599/1599 [==============================] - 0s 39us/sample - loss: 0.4007 - acc: 0.8355 - val_loss: 0.3837 - val_acc: 0.8418\n",
            "Epoch 864/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3957 - acc: 0.8355 - val_loss: 0.4365 - val_acc: 0.8061\n",
            "Epoch 865/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4383 - acc: 0.8049 - val_loss: 0.4018 - val_acc: 0.8293\n",
            "Epoch 866/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4691 - acc: 0.8030 - val_loss: 0.4717 - val_acc: 0.7899\n",
            "Epoch 867/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5056 - acc: 0.7792 - val_loss: 0.4691 - val_acc: 0.7911\n",
            "Epoch 868/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4760 - acc: 0.7942 - val_loss: 0.5049 - val_acc: 0.7830\n",
            "Epoch 869/1000\n",
            "1599/1599 [==============================] - 0s 37us/sample - loss: 0.4940 - acc: 0.7911 - val_loss: 0.4551 - val_acc: 0.7955\n",
            "Epoch 870/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4924 - acc: 0.7849 - val_loss: 0.4711 - val_acc: 0.7942\n",
            "Epoch 871/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4728 - acc: 0.7999 - val_loss: 0.4457 - val_acc: 0.8086\n",
            "Epoch 872/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4423 - acc: 0.8161 - val_loss: 0.4257 - val_acc: 0.8130\n",
            "Epoch 873/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.4226 - acc: 0.8136 - val_loss: 0.4085 - val_acc: 0.8186\n",
            "Epoch 874/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4251 - acc: 0.8105 - val_loss: 0.4083 - val_acc: 0.8318\n",
            "Epoch 875/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4160 - acc: 0.8193 - val_loss: 0.3900 - val_acc: 0.8393\n",
            "Epoch 876/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3963 - acc: 0.8393 - val_loss: 0.3906 - val_acc: 0.8393\n",
            "Epoch 877/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3982 - acc: 0.8330 - val_loss: 0.3911 - val_acc: 0.8380\n",
            "Epoch 878/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.3935 - acc: 0.8293 - val_loss: 0.3729 - val_acc: 0.8468\n",
            "Epoch 879/1000\n",
            "1599/1599 [==============================] - 0s 41us/sample - loss: 0.3868 - acc: 0.8380 - val_loss: 0.3945 - val_acc: 0.8418\n",
            "Epoch 880/1000\n",
            "1599/1599 [==============================] - 0s 37us/sample - loss: 0.3996 - acc: 0.8405 - val_loss: 0.3741 - val_acc: 0.8468\n",
            "Epoch 881/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3828 - acc: 0.8399 - val_loss: 0.3693 - val_acc: 0.8537\n",
            "Epoch 882/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3847 - acc: 0.8455 - val_loss: 0.3783 - val_acc: 0.8405\n",
            "Epoch 883/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3811 - acc: 0.8355 - val_loss: 0.3986 - val_acc: 0.8405\n",
            "Epoch 884/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4091 - acc: 0.8268 - val_loss: 0.3690 - val_acc: 0.8443\n",
            "Epoch 885/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3866 - acc: 0.8418 - val_loss: 0.3688 - val_acc: 0.8455\n",
            "Epoch 886/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3849 - acc: 0.8361 - val_loss: 0.4190 - val_acc: 0.8174\n",
            "Epoch 887/1000\n",
            "1599/1599 [==============================] - 0s 38us/sample - loss: 0.4012 - acc: 0.8255 - val_loss: 0.4098 - val_acc: 0.8205\n",
            "Epoch 888/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4189 - acc: 0.8299 - val_loss: 0.4050 - val_acc: 0.8355\n",
            "Epoch 889/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4887 - acc: 0.7917 - val_loss: 0.4156 - val_acc: 0.8280\n",
            "Epoch 890/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5484 - acc: 0.7711 - val_loss: 0.7453 - val_acc: 0.7248\n",
            "Epoch 891/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.5910 - acc: 0.7742 - val_loss: 0.5556 - val_acc: 0.7636\n",
            "Epoch 892/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.5092 - acc: 0.7786 - val_loss: 0.4382 - val_acc: 0.8168\n",
            "Epoch 893/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.5122 - acc: 0.7867 - val_loss: 0.4545 - val_acc: 0.7942\n",
            "Epoch 894/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.4680 - acc: 0.8005 - val_loss: 0.4261 - val_acc: 0.8186\n",
            "Epoch 895/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.4391 - acc: 0.8105 - val_loss: 0.4292 - val_acc: 0.8074\n",
            "Epoch 896/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4167 - acc: 0.8236 - val_loss: 0.4235 - val_acc: 0.8155\n",
            "Epoch 897/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4097 - acc: 0.8186 - val_loss: 0.3898 - val_acc: 0.8349\n",
            "Epoch 898/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.3879 - acc: 0.8330 - val_loss: 0.3765 - val_acc: 0.8393\n",
            "Epoch 899/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.3868 - acc: 0.8318 - val_loss: 0.3771 - val_acc: 0.8505\n",
            "Epoch 900/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3939 - acc: 0.8343 - val_loss: 0.3744 - val_acc: 0.8349\n",
            "Epoch 901/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3824 - acc: 0.8318 - val_loss: 0.3753 - val_acc: 0.8380\n",
            "Epoch 902/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4141 - acc: 0.8193 - val_loss: 0.3955 - val_acc: 0.8311\n",
            "Epoch 903/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3954 - acc: 0.8305 - val_loss: 0.3595 - val_acc: 0.8543\n",
            "Epoch 904/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3773 - acc: 0.8311 - val_loss: 0.3799 - val_acc: 0.8324\n",
            "Epoch 905/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.3944 - acc: 0.8305 - val_loss: 0.3784 - val_acc: 0.8349\n",
            "Epoch 906/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.3827 - acc: 0.8324 - val_loss: 0.3631 - val_acc: 0.8499\n",
            "Epoch 907/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3709 - acc: 0.8393 - val_loss: 0.3500 - val_acc: 0.8524\n",
            "Epoch 908/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3654 - acc: 0.8430 - val_loss: 0.3578 - val_acc: 0.8474\n",
            "Epoch 909/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3785 - acc: 0.8380 - val_loss: 0.3534 - val_acc: 0.8455\n",
            "Epoch 910/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.3793 - acc: 0.8368 - val_loss: 0.3724 - val_acc: 0.8480\n",
            "Epoch 911/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3771 - acc: 0.8361 - val_loss: 0.3651 - val_acc: 0.8487\n",
            "Epoch 912/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3706 - acc: 0.8418 - val_loss: 0.3620 - val_acc: 0.8424\n",
            "Epoch 913/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3780 - acc: 0.8349 - val_loss: 0.3721 - val_acc: 0.8399\n",
            "Epoch 914/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3724 - acc: 0.8412 - val_loss: 0.3545 - val_acc: 0.8487\n",
            "Epoch 915/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3655 - acc: 0.8430 - val_loss: 0.3483 - val_acc: 0.8530\n",
            "Epoch 916/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.3764 - acc: 0.8330 - val_loss: 0.3456 - val_acc: 0.8568\n",
            "Epoch 917/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.3742 - acc: 0.8424 - val_loss: 0.3692 - val_acc: 0.8412\n",
            "Epoch 918/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3624 - acc: 0.8480 - val_loss: 0.3544 - val_acc: 0.8543\n",
            "Epoch 919/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3642 - acc: 0.8505 - val_loss: 0.3678 - val_acc: 0.8386\n",
            "Epoch 920/1000\n",
            "1599/1599 [==============================] - 0s 39us/sample - loss: 0.3888 - acc: 0.8280 - val_loss: 0.3682 - val_acc: 0.8368\n",
            "Epoch 921/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3624 - acc: 0.8437 - val_loss: 0.3432 - val_acc: 0.8599\n",
            "Epoch 922/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3595 - acc: 0.8512 - val_loss: 0.3507 - val_acc: 0.8487\n",
            "Epoch 923/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3614 - acc: 0.8462 - val_loss: 0.3667 - val_acc: 0.8462\n",
            "Epoch 924/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3656 - acc: 0.8480 - val_loss: 0.3582 - val_acc: 0.8587\n",
            "Epoch 925/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3949 - acc: 0.8455 - val_loss: 0.3713 - val_acc: 0.8518\n",
            "Epoch 926/1000\n",
            "1599/1599 [==============================] - 0s 40us/sample - loss: 0.3936 - acc: 0.8399 - val_loss: 0.3982 - val_acc: 0.8412\n",
            "Epoch 927/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4053 - acc: 0.8361 - val_loss: 0.3708 - val_acc: 0.8455\n",
            "Epoch 928/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3875 - acc: 0.8386 - val_loss: 0.3816 - val_acc: 0.8355\n",
            "Epoch 929/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4165 - acc: 0.8236 - val_loss: 0.4059 - val_acc: 0.8143\n",
            "Epoch 930/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4187 - acc: 0.8211 - val_loss: 0.3906 - val_acc: 0.8336\n",
            "Epoch 931/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4349 - acc: 0.8130 - val_loss: 0.4603 - val_acc: 0.7974\n",
            "Epoch 932/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.4277 - acc: 0.8155 - val_loss: 0.3899 - val_acc: 0.8324\n",
            "Epoch 933/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3917 - acc: 0.8349 - val_loss: 0.3538 - val_acc: 0.8468\n",
            "Epoch 934/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3777 - acc: 0.8336 - val_loss: 0.3552 - val_acc: 0.8512\n",
            "Epoch 935/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3715 - acc: 0.8418 - val_loss: 0.3600 - val_acc: 0.8443\n",
            "Epoch 936/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3783 - acc: 0.8412 - val_loss: 0.3605 - val_acc: 0.8480\n",
            "Epoch 937/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3653 - acc: 0.8474 - val_loss: 0.3452 - val_acc: 0.8574\n",
            "Epoch 938/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3568 - acc: 0.8493 - val_loss: 0.3478 - val_acc: 0.8537\n",
            "Epoch 939/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3559 - acc: 0.8462 - val_loss: 0.3529 - val_acc: 0.8512\n",
            "Epoch 940/1000\n",
            "1599/1599 [==============================] - 0s 37us/sample - loss: 0.3594 - acc: 0.8474 - val_loss: 0.3629 - val_acc: 0.8424\n",
            "Epoch 941/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3728 - acc: 0.8474 - val_loss: 0.3579 - val_acc: 0.8437\n",
            "Epoch 942/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3735 - acc: 0.8474 - val_loss: 0.3851 - val_acc: 0.8324\n",
            "Epoch 943/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3735 - acc: 0.8368 - val_loss: 0.3420 - val_acc: 0.8543\n",
            "Epoch 944/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.3524 - acc: 0.8468 - val_loss: 0.3339 - val_acc: 0.8574\n",
            "Epoch 945/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3564 - acc: 0.8443 - val_loss: 0.3616 - val_acc: 0.8430\n",
            "Epoch 946/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3609 - acc: 0.8487 - val_loss: 0.3399 - val_acc: 0.8530\n",
            "Epoch 947/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.3485 - acc: 0.8505 - val_loss: 0.3362 - val_acc: 0.8543\n",
            "Epoch 948/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3672 - acc: 0.8324 - val_loss: 0.4016 - val_acc: 0.8155\n",
            "Epoch 949/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3620 - acc: 0.8437 - val_loss: 0.3625 - val_acc: 0.8455\n",
            "Epoch 950/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.3601 - acc: 0.8380 - val_loss: 0.3339 - val_acc: 0.8593\n",
            "Epoch 951/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3538 - acc: 0.8405 - val_loss: 0.3591 - val_acc: 0.8437\n",
            "Epoch 952/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3668 - acc: 0.8480 - val_loss: 0.3451 - val_acc: 0.8524\n",
            "Epoch 953/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3649 - acc: 0.8462 - val_loss: 0.3997 - val_acc: 0.8243\n",
            "Epoch 954/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3886 - acc: 0.8311 - val_loss: 0.3680 - val_acc: 0.8386\n",
            "Epoch 955/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4001 - acc: 0.8311 - val_loss: 0.4410 - val_acc: 0.8111\n",
            "Epoch 956/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.4158 - acc: 0.8243 - val_loss: 0.4020 - val_acc: 0.8193\n",
            "Epoch 957/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3878 - acc: 0.8299 - val_loss: 0.3605 - val_acc: 0.8305\n",
            "Epoch 958/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3583 - acc: 0.8430 - val_loss: 0.3388 - val_acc: 0.8518\n",
            "Epoch 959/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3451 - acc: 0.8518 - val_loss: 0.3321 - val_acc: 0.8580\n",
            "Epoch 960/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3465 - acc: 0.8549 - val_loss: 0.3382 - val_acc: 0.8555\n",
            "Epoch 961/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.3302 - acc: 0.8612 - val_loss: 0.3285 - val_acc: 0.8630\n",
            "Epoch 962/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3368 - acc: 0.8587 - val_loss: 0.3183 - val_acc: 0.8624\n",
            "Epoch 963/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3524 - acc: 0.8562 - val_loss: 0.3337 - val_acc: 0.8624\n",
            "Epoch 964/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3391 - acc: 0.8568 - val_loss: 0.3472 - val_acc: 0.8680\n",
            "Epoch 965/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3635 - acc: 0.8537 - val_loss: 0.3539 - val_acc: 0.8468\n",
            "Epoch 966/1000\n",
            "1599/1599 [==============================] - 0s 40us/sample - loss: 0.3577 - acc: 0.8412 - val_loss: 0.3614 - val_acc: 0.8530\n",
            "Epoch 967/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.3649 - acc: 0.8443 - val_loss: 0.3630 - val_acc: 0.8449\n",
            "Epoch 968/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3545 - acc: 0.8537 - val_loss: 0.3821 - val_acc: 0.8374\n",
            "Epoch 969/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.3995 - acc: 0.8368 - val_loss: 0.3701 - val_acc: 0.8474\n",
            "Epoch 970/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3843 - acc: 0.8405 - val_loss: 0.3456 - val_acc: 0.8524\n",
            "Epoch 971/1000\n",
            "1599/1599 [==============================] - 0s 30us/sample - loss: 0.3546 - acc: 0.8518 - val_loss: 0.3495 - val_acc: 0.8524\n",
            "Epoch 972/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3540 - acc: 0.8543 - val_loss: 0.3530 - val_acc: 0.8512\n",
            "Epoch 973/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3551 - acc: 0.8487 - val_loss: 0.3340 - val_acc: 0.8537\n",
            "Epoch 974/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.3382 - acc: 0.8543 - val_loss: 0.3312 - val_acc: 0.8630\n",
            "Epoch 975/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3480 - acc: 0.8505 - val_loss: 0.3255 - val_acc: 0.8593\n",
            "Epoch 976/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3389 - acc: 0.8580 - val_loss: 0.3177 - val_acc: 0.8693\n",
            "Epoch 977/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3338 - acc: 0.8549 - val_loss: 0.3335 - val_acc: 0.8593\n",
            "Epoch 978/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3409 - acc: 0.8549 - val_loss: 0.3353 - val_acc: 0.8580\n",
            "Epoch 979/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3463 - acc: 0.8493 - val_loss: 0.3272 - val_acc: 0.8612\n",
            "Epoch 980/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3850 - acc: 0.8336 - val_loss: 0.4383 - val_acc: 0.8149\n",
            "Epoch 981/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4065 - acc: 0.8286 - val_loss: 0.3724 - val_acc: 0.8443\n",
            "Epoch 982/1000\n",
            "1599/1599 [==============================] - 0s 35us/sample - loss: 0.4303 - acc: 0.8136 - val_loss: 0.4927 - val_acc: 0.7911\n",
            "Epoch 983/1000\n",
            "1599/1599 [==============================] - 0s 38us/sample - loss: 0.4000 - acc: 0.8330 - val_loss: 0.3601 - val_acc: 0.8474\n",
            "Epoch 984/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3786 - acc: 0.8336 - val_loss: 0.3533 - val_acc: 0.8580\n",
            "Epoch 985/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3714 - acc: 0.8530 - val_loss: 0.3564 - val_acc: 0.8499\n",
            "Epoch 986/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3808 - acc: 0.8493 - val_loss: 0.3781 - val_acc: 0.8512\n",
            "Epoch 987/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3860 - acc: 0.8480 - val_loss: 0.3948 - val_acc: 0.8405\n",
            "Epoch 988/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3855 - acc: 0.8487 - val_loss: 0.3993 - val_acc: 0.8443\n",
            "Epoch 989/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.4064 - acc: 0.8462 - val_loss: 0.3697 - val_acc: 0.8474\n",
            "Epoch 990/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.3785 - acc: 0.8393 - val_loss: 0.3474 - val_acc: 0.8693\n",
            "Epoch 991/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3550 - acc: 0.8637 - val_loss: 0.3402 - val_acc: 0.8599\n",
            "Epoch 992/1000\n",
            "1599/1599 [==============================] - 0s 36us/sample - loss: 0.3473 - acc: 0.8549 - val_loss: 0.3602 - val_acc: 0.8468\n",
            "Epoch 993/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3676 - acc: 0.8493 - val_loss: 0.3392 - val_acc: 0.8618\n",
            "Epoch 994/1000\n",
            "1599/1599 [==============================] - 0s 32us/sample - loss: 0.3714 - acc: 0.8430 - val_loss: 0.3510 - val_acc: 0.8543\n",
            "Epoch 995/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.4134 - acc: 0.8368 - val_loss: 0.3513 - val_acc: 0.8549\n",
            "Epoch 996/1000\n",
            "1599/1599 [==============================] - 0s 34us/sample - loss: 0.3799 - acc: 0.8480 - val_loss: 0.3701 - val_acc: 0.8418\n",
            "Epoch 997/1000\n",
            "1599/1599 [==============================] - 0s 31us/sample - loss: 0.3665 - acc: 0.8462 - val_loss: 0.3972 - val_acc: 0.8418\n",
            "Epoch 998/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3843 - acc: 0.8430 - val_loss: 0.3721 - val_acc: 0.8505\n",
            "Epoch 999/1000\n",
            "1599/1599 [==============================] - 0s 41us/sample - loss: 0.4112 - acc: 0.8311 - val_loss: 0.3627 - val_acc: 0.8505\n",
            "Epoch 1000/1000\n",
            "1599/1599 [==============================] - 0s 33us/sample - loss: 0.3628 - acc: 0.8505 - val_loss: 0.3341 - val_acc: 0.8668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3gU5fbA8e8hhIQqvQgiAoqXLkYU\nBXsBrui9iiICUsV6sV7FclXE7u+qiF6xoaIIKKigCIiiIp2AdER6M0CIEgKk7/n9MZvd9Cwhm91k\nzud55smUd2bO7MCenXnfeUdUFWOMMe5VIdQBGGOMCS1LBMYY43KWCIwxxuUsERhjjMtZIjDGGJer\nGOoAjlfdunW1WbNmoQ7DGGPKlBUrVhxU1Xr5LStziaBZs2bExsaGOgxjjClTRGRnQcvs1pAxxric\nJQJjjHE5SwTGGONyZa6OwBgTPtLT09mzZw8pKSmhDsV4RUdH06RJEyIjIwNexxKBMabY9uzZQ/Xq\n1WnWrBkiEupwXE9VSUhIYM+ePZx22mkBr2e3howxxZaSkkKdOnUsCYQJEaFOnTrHfYUWtEQgItEi\nskxEVovIehEZlU+ZQSISLyKrvMOwYMVjjAkOSwLhpTjnI5i3hlKBS1X1iIhEAgtEZJaqLslVboqq\n3h3EOIwxxhQiaFcE6jjinYz0DqF7+cGPP8KFF8L27SELwRhTshISEujYsSMdO3akYcOGNG7c2Ded\nlpYW0DYGDx7Mpk2bCi3z5ptvMnHixJIIma5du7Jq1aoS2VZJCWplsYhEACuAlsCbqro0n2LXi8iF\nwO/Afaq6O5/tDAeGAzRt2rR4wRw8CL/8AkePFm99Y0zYqVOnju9L9amnnqJatWo8+OCDOcqoKqpK\nhQr5/+794IMPitzPXXfddeLBhrGgVharaqaqdgSaAJ1FpG2uIl8DzVS1PTAX+KiA7byjqjGqGlOv\nXr5dZRQt676ZvZHNmHJvy5YttG7dmn79+tGmTRvi4uIYPnw4MTExtGnThqefftpXNusXekZGBjVr\n1mTkyJF06NCBLl26cODAAQAef/xxXnvtNV/5kSNH0rlzZ1q1asWiRYsAOHr0KNdffz2tW7emd+/e\nxMTEBPzLPzk5mYEDB9KuXTs6derE/PnzAVi7di3nnHMOHTt2pH379mzbto2kpCR69OhBhw4daNu2\nLVOnTj3hz6tUmo+q6iER+RHoDqzLNj8hW7H3gJeCFoQlAmOC7+KL88678Ua48044dgx69sy7fNAg\nZzh4EHr3zrnsp5+KHcpvv/3GhAkTiImJAeCFF16gdu3aZGRkcMkll9C7d29at26dY53ExEQuuugi\nXnjhBe6//37Gjx/PyJEj82xbVVm2bBkzZszg6aefZvbs2YwdO5aGDRsybdo0Vq9eTadOnQKO9fXX\nXycqKoq1a9eyfv16evbsyebNm/nf//7Hgw8+SJ8+fUhNTUVVmT59Os2aNWPWrFm+mE9UMFsN1ROR\nmt7xysAVwG+5yjTKNnkNsDFY8VgiMMZdWrRo4UsCAJMmTaJTp0506tSJjRs3smHDhjzrVK5cmR49\negBw9tlns2PHjny3fd111+Ups2DBAm666SYAOnToQJs2bQKOdcGCBfTv3x+ANm3acPLJJ7NlyxbO\nP/98nnnmGV566SV2795NdHQ07du3Z/bs2YwcOZKFCxdy0kknBbyfggTziqAR8JG3nqAC8JmqfiMi\nTwOxqjoDGCEi1wAZwJ/AoKBFU7s2xMRA5cpB24UxrlfYL/gqVQpfXrfuCV0B5Fa1alXf+ObNmxkz\nZgzLli2jZs2a9O/fP9+29pUqVfKNR0REkJGRke+2o6KiiixTEgYMGECXLl2YOXMm3bt3Z/z48Vx4\n4YXExsby7bffMnLkSHr06MGjjz56QvsJWiJQ1TXAWfnMfyLb+CPAI8GKIYeLL4bly0tlV8aY8HL4\n8GGqV69OjRo1iIuLY86cOXTv3r1E93HBBRfw2Wef0a1bN9auXZvvFUdBunXrxsSJE7nwwgvZuHEj\ncXFxtGzZkm3bttGyZUvuuecetm/fzpo1a2jRogV169ZlwIABVK9enU8++eSEY7cuJowx5V6nTp1o\n3bo1Z555JqeeeioXXHBBie/jX//6F7fccgutW7f2DQXdtrnqqqt8fQF169aN8ePHc9ttt9GuXTsi\nIyOZMGEClSpV4tNPP2XSpElERkZy8skn89RTT7Fo0SJGjhxJhQoVqFSpEuPGjTvh2EXL2D3zmJgY\nLdaLaX7+Ge69FyZNgjPPLPnAjHGhjRs38re//S3UYYSFjIwMMjIyiI6OZvPmzVx55ZVs3ryZihVL\n//d2fudFRFaoakx+5d1zRZCYCKtWOS0XjDGmhB05coTLLruMjIwMVJW33347JEmgOMpGlCXBWg0Z\nY4KoZs2arFixItRhFIt7eh+1RGCMMflyTyLIYonAGGNycE8iqFsXLrkEqlcPdSTGGBNW3FNHcN55\nMG9eqKMwxpiw454rAmNMuVMS3VADjB8/nn379uW7rH///nz11VclFXJYck8imD8fWraEX38NdSTG\nmBKS1Q31qlWruP3227nvvvt809m7iyhKYYnADdyTCI4dg61b4Tjf5WmMKZs++ugjOnfuTMeOHbnz\nzjvxeDxkZGQwYMAA2rVrR9u2bXn99deZMmUKq1atok+fPgFfSXg8Hu6//37atm1Lu3btfF1B7927\nl65du9KxY0fatm3LokWL8t1nuHFPHYE1HzUmqO6913lmsyR17Aje1wAcl3Xr1vHll1+yaNEiKlas\nyPDhw5k8eTItWrTg4MGDrF27FoBDhw5Rs2ZNxo4dyxtvvEHHjh0D2v7nn3/Oxo0bWb16NfHx8Zxz\nzjlceOGFfPLJJ/Tq1YuHH36YzMxMkpOTWbFiRZ59hhv3XBHYC7aNcY3vv/+e5cuXExMTQ8eOHfn5\n55/ZunUrLVu2ZNOmTYwYMYI5c+YUuwvnBQsW0LdvXyIiImjYsCFdu3YlNjaWc845h/fee49Ro0ax\nbt06qlWrVmL7DCb3XBFksSsCY4KiOL/cg0VVGTJkCKNHj86zbM2aNcyaNYs333yTadOm8c4775TY\nfi+99FJ++uknZs6cyS233MJDDz1Ev379grrPkuCeK4L69eGaa6BWrVBHYowJsssvv5zPPvuMgwcP\nAk7rol27dhEfH4+qcsMNN/D000+zcuVKAKpXr05SUlLA2+/WrRuTJ0/G4/Gwf/9+Fi5cSExMDDt3\n7qRhw4YMHz6cwYMH8+uvvxa4z3DiniuCjh1h+vRQR2GMKQXt2rXjySef5PLLL8fj8RAZGcm4ceOI\niIhg6NChqCoiwosvvgjA4MGDGTZsGJUrV2bZsmV5WhwNGzaMu+++G4DTTjuNn3/+mSVLltC+fXtE\nhFdeeYX69eszfvx4XnnlFSIjI6levToff/wxu3fvznef4cQ93VAbY0qcdUMdno63G2r33BpasAAa\nNIDFi0MdiTHGhBX3JIK0NDhwwPlrjDHGxz2JwJ4jMCYoytrt5fKuOOfDEoExptiio6NJSEiwZBAm\nVJWEhASio6OPaz33tBqyRGBMiWvSpAl79uwhPj4+1KEYr+joaJo0aXJc6wQtEYhINDAfiPLuZ6qq\nPpmrTBQwATgbSAD6qOqOoATUoAH06+f8NcaUiMjISE477bRQh2FOUDCvCFKBS1X1iIhEAgtEZJaq\nLslWZijwl6q2FJGbgBeBPkGJ5swz4ZNPgrJpY4wpy4JWR6COI97JSO+Q+77MtcBH3vGpwGUi1imQ\nMcaUpqBWFotIhIisAg4Ac1V1aa4ijYHdAKqaASQCdfLZznARiRWR2GLfi1y8GKpWhR9+KN76xhhT\nTgU1Eahqpqp2BJoAnUWkbTG3846qxqhqTL169YoXjMfjvJMgM7N46xtjTDlVKs1HVfUQ8CPQPdei\nvcApACJSETgJp9K45FmrIWOMyVfQEoGI1BORmt7xysAVwG+5is0ABnrHewPzNFgNkq3qwRhj8hXM\nVkONgI9EJAIn4Xymqt+IyNNArKrOAN4HPhaRLcCfwE1BjMdhVwTGGJND0BKBqq4Bzspn/hPZxlOA\nG4IVQw4NGsBtt8Epp5TK7owxpqxwz5PFzZvDuHGhjsIYY8KOe/oaUnVaDtmtIWOMycE9iSA2FiIi\n4NtvQx2JMcaEFfckgix2RWCMMTm4JxHYcwTGGJMvSwTGGONylgiMMcbl3JMIGjSABx+EFi1CHYkx\nxoQV9zxH0LgxvPxyqKMwxpiw454rgsxMSEyE9PRQR2KMMWHFPYlg/XqoWRO+/jrUkRhjTFhxTyLI\nYpXFxhiTg3sSgbUaMsaYfLkvERhjjMnBPYkgi10RGGNMDu5JBPXrw6hR0Lp1qCMxxpiw4p7nCOrX\nhyeeKLqcMca4jHuuCNLTYc8eOHYs1JEYY0xYcU8i2LrVeU3ljBmhjsQYY8KKexJBFqssNsaYHNyT\nCOw5AmOMyZclAmOMcbmgJQIROUVEfhSRDSKyXkTuyafMxSKSKCKrvEPwmvVYIjDGmHwFs/loBvCA\nqq4UkerAChGZq6obcpX7RVWvDmIcjnr14JVX4Oyzg74rY4wpS4KWCFQ1DojzjieJyEagMZA7EZSO\nmjXhvvtCsmtjjAlnpVJHICLNgLOApfks7iIiq0Vkloi0KWD94SISKyKx8fHxxQsiLQ02boRDh4q3\nvjHGlFNBTwQiUg2YBtyrqodzLV4JnKqqHYCxwFf5bUNV31HVGFWNqVevXvEC2bvX6V5i+vTirW+M\nMeVUUBOBiETiJIGJqvpF7uWqelhVj3jHvwUiRaRuMGOyymJjjMkpmK2GBHgf2KiqrxRQpqG3HCLS\n2RtPQpACcv5aIjDGmByC2WroAmAAsFZEVnnnPQo0BVDVcUBv4A4RyQCSgZtUg/RNbe8jMMaYfAWz\n1dACoNBvX1V9A3gjWDEUsNNS3Z0xxoQ79zxZXKcOvPsuXHBBqCMxxpiw4p73EVSrBsOGhToKY4wJ\nO+65IkhLg2XL4MCBUEdijDFhxT2JID4ezj0Xvsr3UQVjjHEt9yQCazVkjDH5ck8iyGKthowxJgf3\nJAJ7oMwYY/JlicAYY1zOPc1Ha9aEyZPtfQTGGJOLexJBdDT06RPqKIwxJuy459ZQWhrMmwd79oQ6\nEmOMCSvuSQSHD8Nll9lzBMYYk4trEsHW7RX4H3fw55FKoQ7FGGPCimsSwcq1kdzF//jjUJVQh2KM\nMWHFNYkgIsL5m+mxJ4yNMSY79ySCik4CsERgjDE5uScRVI0GILPrRSGOxBhjwot7EkGU88hEZsPG\nIY7EGGPCi3sSgWYAkLnTniMwxpjs3JMIMlIByJy/MMSRGGNMeHFPIrBWQ8YYky/3JIKsVkOZIQ7E\nGGPCTECJQERaiEiUd/xiERkhIjWLWOcUEflRRDaIyHoRuSefMiIir4vIFhFZIyKdincYRbMrAmOM\nyV+gVwTTgEwRaQm8A5wCfFrEOhnAA6raGjgPuEtEWucq0wM43TsMB94KNPDjVTHSSQAZHtdcBBlj\nTEAC/Vb0qGoG8E9grKr+G2hU2AqqGqeqK73jScBGIHfbzWuBCepYAtQUkUK3W1wRlZ0+hjIvuDAY\nmzfGmDIr0ESQLiJ9gYHAN955kYHuRESaAWcBS3Mtagzszja9h7zJAhEZLiKxIhIbHx8f6G5ziKjk\n3BvKrF2vWOsbY0x5FWgiGAx0AZ5V1e0ichrwcSArikg1nFtL96rq4eIEqarvqGqMqsbUq1e8L/II\nnFrizO27irW+McaUVwG9oUxVNwAjAESkFlBdVV8saj0RicRJAhNV9Yt8iuzFqW/I0sQ7r8Q5iSCC\nzGUrgKbB2IUxxpRJgbYa+klEaohIbWAl8K6IvFLEOgK8D2xU1YLKzgBu8bYeOg9IVNW444g/YL5b\nQxn28npjjMku0HcWn6Sqh0VkGE7l7pMisqaIdS4ABgBrRWSVd96jeH+Oq+o44FugJ7AFOIZzCyoo\nLBEYY0z+Ak0EFb2teW4EHgtkBVVdABTaaF9VFbgrwBhOiO85gnRPaezOGGPKjEAri58G5gBbVXW5\niDQHNgcvrJLnSwR2RWCMMTkEWln8OfB5tultwPXBCioYfIng0itCG4gxxoSZQCuLm4jIlyJywDtM\nE5EmwQ6uJPkSQY1aoQ3EGGPCTKC3hj7AaeFzsnf42juvzPAlgo2/hzYQY4wJM4Emgnqq+oGqZniH\nD4Ey9YiuLxEsjQ1tIMYYE2YCTQQJItJfRCK8Q38gIZiBlbSsRJCREdo4jDEm3ASaCIbgNB3dB8QB\nvYFBQYopKCp6q8Wt1ZAxxuQUUCJQ1Z2qeo2q1lPV+qr6D8pqqyF7MY0xxuRwIp3z319iUZSCSk4v\n1KSm2/sIjDEmuxP5VixTr/qqUAEiI5XUK3uFOhRjjAkrJ5IIytzN9uhoIaVitVCHYYwxYaXQJ4tF\nJIn8v/AFqByUiIIoWlJIXbcLOCPUoRhjTNgoNBGoavXSCqQ0RKUeJmXNZiwRGGOMn6tqTqMj0knN\niAh1GMYYE1ZclQiiKmaSkm6JwBhjsnNVIoiumElKRqCvYDDGGHdwVSKIivSQmmlXBMYYk52rfh5H\nt2pKSqq9uN4YY7Jz1RVBdLVIUjMjQx2GMcaEFVclgqgjCaTs3AdpaaEOxRhjwoa7bg0diSc1vgIc\njfJ3PmSMMS7nriuCaCGFaDh6NNShGGNM2AhaIhCR8d73G68rYPnFIpIoIqu8wxPBiiVLdGVvIjh2\nLNi7MsaYMiOYt4Y+BN4AJhRS5hdVvTqIMeQQFV2BVKIsERhjTDZBuyJQ1fnAn8HafnFEV42wW0PG\nGJNLqOsIuojIahGZJSJtCiokIsNFJFZEYuPj44u9s+hWp5JGFNrl/GJvwxhjyptQJoKVwKmq2gEY\nC3xVUEFVfUdVY1Q1pl69esXeYVRl53BT08rUO3WMMSaoQpYIVPWwqh7xjn8LRIpI3WDuMzrzCAAp\nC2KDuRtjjClTQpYIRKShiIh3vLM3loRg7rNyBedBsmO/bgrmbowxpkwJWqshEZkEXAzUFZE9wJNA\nJICqjgN6A3eISAaQDNykqkF9/WWNelEAJCXYk8XGGJMlaIlAVfsWsfwNnOalpaZ6vWgADv+ZUZq7\nNcaYsBbqVkOlqkYtpwvqpEOZIY7EGGPCh7sSQQ3n7+FjrupiyRhjCuWqRFC9uvM38YZhoQ3EGGPC\niKsSQZ06zt+EoLZNMsaYssVViaBmTahUMZP9k38MdSjGGBM2XJUIRKB+pUT2ry9+NxXGGFPeuCoR\nALSq/xezjl2EJoRVf3jGGBMyrksE3f8ewQEacPibn0MdijHGhAXXJYK6f3M6rfvzd6sxNsYYcGEi\nqN2kCgAJ6TVCHIkxxoQH1yWCuvWcLqh7fXwjpFmfQ8YY47pEcPbZzt99+0CiKnFTmzUkJ4c2JmOM\nCSXXJYKoKFi31t/J6ZQN7bnoIuXAgRAGZYwxIeS6RADQpq2w9vEpvunly4Xz2h+1W0XGGFdyZSIA\naDu6D6+/7p/evr8qa+8aF7qAjDEmRFybCAD+9S9yJIP2741g0/LDrFlyLHRBGWNMKXN1IgAnGaxb\n558+s3MNOnSpwsoXvrNbRcYYV3B9IgBo0wbWr8v5lsx3H9nKe1F38fLffyJl614yM6F/f6e/Io4e\nDU2gxhgTBPaGFq/WbYT334c5c+DgtkTGxd7hLPgWDs/7P46c2pqJm3oC8N9qT3Df8n5UiOkUwoiN\nMaZkSJDfF1/iYmJiNDY2Nqj7yMyExYuhW7eCy3xz/zz+fl0UnH++9zLBGGPCl4isUNWY/JbZraF8\nRERA166wdy988EH+Za5+5VIad23GF1e8hcdTuvEZY0xJskRQiJNPhkGDICMD3nwT/vgD7hn4l2/5\nHzTm+h/uZMqQ2bz06F+Mv2c1/fuT40nlQ4fg8OHSj90YYwIVtFtDIjIeuBo4oKpt81kuwBigJ3AM\nGKSqK4vabmncGipKcjLcNSyVSZ9HkJKet5rlhxlHubRXVfjwQ2TwIBrVTeeP+Eh/gbQ0mDgRBg6E\nCpaLjTHBF6pbQx8C3QtZ3gM43TsMB94KYiwlqnJlGD8xiuS0iowcmXf5imue4sDkedw32Ll6iDsY\nCQcPAs4VxuP9tsOQIfDDD3nWTUuDCROw203GmFITtESgqvOBwl4Ddi0wQR1LgJoi0ihY8QTL8887\nX9rJyfDoo868h3iZBn0v5TXu85XbvSEJ+vTho4/g2amtuJI5cPQoTzwBJ53k397jt+5n4ECYNauU\nD8QY41qhvC/RGNidbXqPd14eIjJcRGJFJDY+PvzeNywC0dHw7LPw0fsZ+ZZ5/DEPnT97wDc9lyvJ\nXLWW0aOdOoSU9VsB+H5BFABpidYlqjGmdJSJG9Sq+o6qxqhqTL169UIdTqFuGVKR5GR47z1YswZU\n4ayzYMKCFiync46yFUf9xze++h9PMvU/q/l1W00A/ly8CXAqqkXg9tthzJjA41CF3buLLmeMMaFM\nBHuBU7JNN/HOK/Oio2HoUGjXzpl++2248kp49RUPs55Zwfi30/Osc96WT7jhmQ6+6c3TN5CeDlkX\nQG+/Dffem+uh5tRUJ1Pk49tvoWlTmDatpI7KGFNehTIRzABuEcd5QKKqxoUwnqA55xznieV776tA\n98fO5pahkdx3H5x7Lnz6KVzby0OfTr/nWOfF3Tdzcu1kHm/7VY75cbc87DzxtmsXREfjGf0s+1fF\nwZQp/LFXmT4dZs+GPZucjDF1zJ5SO05jTBmlqkEZgElAHJCOc/9/KHA7cLt3uQBvAluBtUBMINs9\n++yztbxaskT14YdVh/dLUufmTt5hKO/qjpaX6cdDf9S2rPHNn0mPHOVee/gPBdXr+Vx14kRnB+np\nqo8/rnM+PagvvRTaYw2Ux6N6992qK1eGOhJjyjYgVgv4XrUuJsJU3K50Tm1ZkfT04nVf8UjfHTw/\nqRkAC2r05IJDM1kydjn/uSeR77kCgJEjnVZPhTl61LlqGTYsND1p/PUX1K7tjJexf6rGhBXrYqIM\natQ0krQ08TVNnTcP7rkn/7LPP5aUd543CQB0Pfwtix+fyZBnm/uSAMALL5DjsecNGyAy0mkGm/Uc\nw/33w/Dh8NNPJXBQxWA9gRsTfHZFUAalpjq/zjdsgObNoUYNp4XQ6tUwaJCSkBD4T/ftNKPpwzcz\nescAZi+qwZLdTgveyZOhT69jXNQqjvl7WvDgP7dwoHIzXnm9IqmpTvcbWZ55xpkeMqSkjxR27oRm\nzZzxMvZP1ZiwUtgVgSWCcuiXX+Drr+GSS5yWS6ecUvQ6ud14o/LZZwUnlKx/NgcPQlaLXs3IdNrM\nnnVWnrJLl8J55x1/HL//Dq1a5dynMeb42a0hl+nWDV56CXr0gCZNICnJaUY6c6bT4GjhQqd5a2EK\nSwIAm+50Hmp4pM8237yODf7grU7vsOvzpYDzxf3nn/DW6+l06QKzP8u/970ZX3l49aE/8l2Wmuof\nT0m2TGBMUBRUixyuQ3luNVTaUlJUt29X/eYb1REjVOvV8yio3nqr6jW9MvWFaxYW2HoJVIdduqXA\nZVPuW6z/uiNdQfVCflJQfZehmpGW6Q9g3jzVY8d86yTMX6cej2rr1v6GTsuW+be587MlOeI/dEh1\n797Cj/HWW1UffbRkPzdjyiKs1ZAJhGrelkE7d8KKFc4v85tvdh5se+apdHbH+XtTHdx+BR+sOTug\nfVzZ9Sj/vXklc9/bSdOEX7nyvRupccW5ACwZNYcz/nWVr5XQ5s2wb5//BUFL/z2Vzi/19m3rjDOc\nMoX9E846Ht1/AOrXDyhGY8qjwm4NhfwX/vEOdkUQeps3q7Zrk6GgescdqpmZqlOmqL7xhmqPHh69\n4fqMQq8kChqmTXOG7PO+G73ENz6jx/80KUl1zhwnjqz5R47kjO+PP1Q7d1bds8dfRkeMCOpnMnq0\n6nfflew2H3rI+VyNKQkUckUQ8i/24x0sEYQ/j0f1sm6pvi/hevVUx4xR/fe/jz85ZB8G876edYbz\nsN3sJ/23rWKnbnfuE23erKqqTz3lzH9o4D5fmcR+d+SI8euvVfftK7lj9iWctLSS36YxJaCwRGCV\nxabEicDseZXYvNl5HuHAARgxwqnAnjcPHnxAiV2u3HkntGgBK1cG1vT0A4bw6+/VAOg+6nzf/Jje\nzXjjvE/IPL2V8+CBOg9BvPRRA1+ZlRsr+8aPHYNevaDFqXn7fCoOzX5ravHiEtnm8bjuOvjPf4ou\nZ4onJQV27Ah1FEFWUIYI18GuCMqnjAzVIYMytdUZmb5fwi+N8lckT52cXuQVw41M1qNU1kc7zsx3\n+cIXf9FXnzumt9ycXuCv7eQjGZqRcXyxJydn+/XureXOzCx8nUAEekVgVw7BdcMNzuebmhrqSE4M\ndmvIlCWJiaoJCc64x6O6dat//JFHnH+1rU9P1f79PQHdUurUqeBlmpmpmpKiHo+qLnHqI/q2WqFH\nj6oeOxZYvPHx/u0deHyMLl7sjC9YUPzPwOOxRBAuqlZ1Pt/Dh0MdyYkpLBHYrSETdmrU8PcvJOI8\nPZ01/txzzrMQazZW4uOPhTf/m8ILg37L762fPt99V/CyjyMGMrjODE4+WXnw9iMATNrUiapVoUoV\nmH3PLDhyhGMLV7J5c/7b+PJL//iaNf7uOE6kC/Dsz0+Y0IqIcP6ml8ydxLBkzUdNubF3L4wfD1df\nDe3bO/N27HDqIRYvhvPPL3T1gKTPmMWEsYlc+3g76pxeGxo1ytHkdsJbR9m9IYnHxjYEnPqIypUL\n2FghDh2CWrWc8aL+i/qayJat/8plRq1azvn44w9oVOZeputnTxYbV2jc2Kk0Pess51dcRISTBAC6\ndHG+KPdtT+bG3plMmVK8ffS95ghD595E84uasPfkGNIP/JVj+ZwfI31JAGDuvTPh4EE2bYJ+/QL/\npZ+a4v9WF3Gep8hPVueAJniyrgjK81WaJQLjKg2aVWbK5xHceKPTUd+XX8JbbzlXEpdf7rQmuuMO\n+Oc//b/Is5vKDQAc5iSasJfYfq8CcHP1r2nTBiZ+VilH+aHvdCZj9PMMveEwn34Ky5b5l6nCa4/s\n54t753PFFcrPP/uXpew6kH3ceQQAABCgSURBVGM7S+bm7WEWnBYtPh98EPgHYQJWwfstWZ57wrVb\nQ8YU4dAh5/Wjjz7qJI/27WHqVKc+IMu2V6fz00nX+prB1q2rHDyYt7+m06vu5Ychn/Lz2NUM4JMc\ny5rUT2XLriimT4f2Kcv420D/O64//OdXDPziH/7Cc+ZA06Yk1P8bdes6sxQhJVmJigrNuyNKQloa\nREXBuHFw222hjsbRqJFzRbZmjf/1s2WRPVlsTBA895zqddepvv++M52S4jzAvGKFM539yeZAhjrE\n67+bT3Wazl79c45lLzb4r2ZmeHTlfRNU163T23hLP6wwWHfv8reciqeOb9zjCd3nciLi4tT3EGK4\naNzYiWn58lBHcmKw5qPGhMbmzceXDLKGi2qvyTF9Kd/rQ7ygoPoYo33z183a5Rt/5MpYf1KYtfy4\ns8G+faoLFwbpgwjQli1O/PXrhzaO7Jo2dWIK9WdzogpLBFZHYEwQtWyZ8ys+MRGmT4fO/rs+XHUV\nXHFFzvV+/rOdr6IbYB6X8RIPA/Asj/vmX/53f53E89/5O/4b0eN3dl48MOdGExJg9uwCY21+mocL\nLght66Mkb1VION3aiqjg1Minxv0Z4kiCxxKBMaWoRg245hrnRT379sGTT8IXXzgvEvr+e6dH1SyX\nX+40f33ooYK3t8/jdKNRqVLOb+9J3Eyz+RPYPnMDKRINlSrxn5aTeKXHd6xflMiCBU7T1uyOJTtf\nB/E/roN9+9DZc5xWSb/9VgJHXrTnnoOPP/ZOeDJLZZ+BiMh0aolTZ34f4kiCqKBLhXAd7NaQKe/+\n/FP1tddU//rLP2/OHNU773S6OXjqKacuwtcVx0tOmQMHVBfNz78rjgbE5Zl3xhmqb4+K06VjFquq\nf/6yIW+ptmih57HIuXkcE+Pcs/Hq1Uv17rtL/rizx9YwMr7I8jNnqlau7PQ3GExntHA+0+m3fxvc\nHQUZoaojALoDm4AtwMh8lg8C4oFV3mFYUdu0RGCMIz1ddf78vPNbtFAdMCDw+oiKpOk3j/p7c/3w\nxpk6j4t901czQ/988jVn4/Pm+eZ7O3stVPZqiilTVFu18uTbl1P2LjVAtSF/FNlh0xlnOGVXriw6\njhPRpmWygurkm74M7o6CLCSJAIgAtgLNgUrAaqB1rjKDgDeOZ7uWCIwpnMfjDN27B54Miho6Easb\nbh+jX/AP37xzzsnVH9O2bc7r4Lxf4Lt3O+UmT3YWV6nsdCi48+1ZeWJOSsq5v0qkqO7cWehxVq/m\ntJhavLAEevgrRKf6ToX8+B6fBXU/wVZYIghmHUFnYIuqblPVNGAycG0Q92eMwaloFYFZs5wnjxMS\n4P77Ye5cp/uN7HqeV3AF6MBsdc0rOZvW40ZwHf6OlZYvhz7dE9lw3eN4vvmWo1ddx5Hnxvhu9K9b\n55S76SbYvh2qRzn32je/+IWzIDHRV1HxZ64w0oji2O97Coxt/nxIOuLUKB/+cUWB5QKlB+KZ/ewK\nMjLyLqvkcR4pPuopRl8hZUQwE0FjYHe26T3eebldLyJrRGSqiJwSxHiMcR0RpwO///7XqXz++ms4\ncgTi450kMXNxbQ4fdl5BesklOR/ieuQRp4O/iy8uePtfzz+JNl8+Q0SvnlTb/CvVOcL+QQ+RtmoD\nPXr4yzVvDvsPRQOwIrUtGRmQ3qip0x8IsHv94Tzb3ruigH41gIsu8o8n1m4WyEdRqNkXv0CPx8/m\nvz3yVghHeZIBONqp2wnvJxBbt8Lzz5du661Qtxr6Gmimqu2BucBH+RUSkeEiEisisfHx8aUaoDHl\nTdWqULeuv4lm9eowfLjz0qBx42DDBvjoI2jVyule4bvvnARSpUpg22/Ifq4+q+Bf8w/vHUH3i45R\nKTmRt3+/mENxySyacTBPuQn7ruTll/3TV1+tfDx4Hpmxv+YoN35GXXpfmkD2n/NpabBwoTPetSuM\nHVt4zHM3Or9RZy85Kc+yyAwnERyTqqXSz0T37s5T7KX6VVfQPaMTHYAuwJxs048AjxRSPgJILGq7\nVkdgTGh4PKqbNqkuXap67bWqN95YdN1Cn15HiyxTt1a6/qPuLwUuj+t1qx494n+C+mBEfQXV5xuP\nzVFuzd9H+mJ94AFn3q9LUnzLNSnJt/yTT1QjI/11HNWq+N+znbsy+9LKTkX6P5nmNFUKwKuvqq5b\nV7zPuW5dJ469e4u3fkEIUWVxRWAbcBr+yuI2uco0yjb+T2BJUdu1RGBMeMjMVN2wwXmJ0KxZqkeO\nON1sNGnifLM89ZjzSq8pU5zpyy7z6IQJBSeEKJJ945dcknPZ51yfp/zHYxK0fZXf/etXysxb5oFf\n/Ylg1Son8H37tEmVBAXVtQsTNTMz5zprJ63NcZwXtkvwLfOMeb3IzyU11SlbvXr+T3b/9lvh3VVk\n7Stbi90SEZJE4OyXnsDvOK2HHvPOexq4xjv+PLDemyR+BM4sapuWCIwJbx6PkxCy273b35R08WLV\nN95wEsfWrf4vvoY1juiBA07jo927VS+6qOCkAapz56ruX/B7oWUu4QffeMpd96vGx+vWKm19876Y\nlKIvjXYS0BmnpSqovstQX8snj0e1c2f/9sZ2nVzk8cft9Sek/BS2LCEhW0Jam3+Z4gpZIgjGYInA\nmPLF41EdPVp16tS8y0aPzvnFvn69f3zPHqdMUpLqO+8UnjSyhheHb8kxXatioraq6Txsd0nbA1q3\nUqK2Y7V6Jk1WTU7Wmztt8P26B9UmFf9QHTVKdfz4Ao9n0ZRdASWCzEN53325c6d/+dLFmaqxsc69\nuFtvVX3iibwZ9jhYIjDGlFmLFjlPD+/a5UxPm+Y83ZynT730dD0Yl6affx5YUsg9DLomQW+4znmK\nuDNL9I52/nqLZ+7cq09e+6sKmfoeQ/Q7Lvd3M5vN3N7jcmwz+xvvzz1XtUMH/7I/PvvFWbBwoWq3\nbqpJSbpxo3/5pS126F2MVQV9hkd1Or1UP/ig2J+jJQJjjGt4PKrLlqnu2OHcgkpNVd27y18Z3LOn\nM+/VV3MmgsQDKRofnzdBnMtizUzP1CnvJ+WYH9uwp+7o85DG9b7beWrO48mzrg4YoHf2P6TntE7K\ns2zxA5+rqupr7d/XUfxH9dNPdfkvyXnKJdVs4t/ee+8V+3OxRGCMcb24uBw/0FVV9ehR50f2nDn+\neTNn5vwivvNa5x5UYqJq7dp5E0Vhw/+4vcBlk+5fpgmT5vim/+x7p/704fY85XpFzPSNH3rylWIf\nf2GJINTPERhjTKlo2BAq5XyTKFWqwKBBcOWV/nk9ezpvI3vrLXjmGRg51nnGoEYN2L+/6Den9emZ\nxBtvOON38laB5dYcac6tff2vIK096U0OTc7bTfjXmT194/Pb3FH4zouroAwRroNdERhjQi0uzmnV\n9P33qsOGOb2gguqQwR71eJwK7JdfVm3YULVNm7xXA82b+8fvr/pWnuVjXz6mS5f6pxuf7Nx2eu65\n4sdMIVcE9s5iY4wpAenpEBmZd35mJowc6X/pznPPwapVcNllzvS2lYdo0KomrVrBHu8D2QkJTtcg\n8fHOE9I9e8KwYdCjB/TtW7z4CntnsSUCY4wJgeXLnS/5e+91pvfuhRdfhFGjoFatkt+fJQJjjHG5\nwhKBVRYbY4zLWSIwxhiXs0RgjDEuZ4nAGGNczhKBMca4nCUCY4xxOUsExhjjcpYIjDHG5crcA2Ui\nEg/sLObqdYG8b8ku3+yY3cGO2R1O5JhPVdV6+S0oc4ngRIhIbEFP1pVXdszuYMfsDsE6Zrs1ZIwx\nLmeJwBhjXM5tieCdUAcQAnbM7mDH7A5BOWZX1REYY4zJy21XBMYYY3KxRGCMMS7nmkQgIt1FZJOI\nbBGRkaGOpySIyCki8qOIbBCR9SJyj3d+bRGZKyKbvX9reeeLiLzu/QzWiEin0B5B8YlIhIj8KiLf\neKdPE5Gl3mObIiKVvPOjvNNbvMubhTLu4hKRmiIyVUR+E5GNItKlvJ9nEbnP++96nYhMEpHo8nae\nRWS8iBwQkXXZ5h33eRWRgd7ym0Vk4PHG4YpEICIRwJtAD6A10FdEWoc2qhKRATygqq2B84C7vMc1\nEvhBVU8HfvBOg3P8p3uH4cBbpR9yibkH2Jht+kXgVVVtCfwFDPXOHwr85Z3/qrdcWTQGmK2qZwId\ncI693J5nEWkMjABiVLUtEAHcRPk7zx8C3XPNO67zKiK1gSeBc4HOwJNZySNgBb3VvjwNQBdgTrbp\nR4BHQh1XEI5zOnAFsAlo5J3XCNjkHX8b6JutvK9cWRqAJt7/IJcC3wCC87RlxdznG5gDdPGOV/SW\nk1Afw3Ee70nA9txxl+fzDDQGdgO1veftG+Cq8niegWbAuuKeV6Av8Ha2+TnKBTK44ooA/z+qLHu8\n88oN76XwWcBSoIGqxnkX7QMaeMfLy+fwGvAQ4PFO1wEOqWqGdzr7cfmO2bs80Vu+LDkNiAc+8N4O\ne09EqlKOz7Oq7gX+D9gFxOGctxWU7/Oc5XjP6wmfb7ckgnJNRKoB04B7VfVw9mXq/EQoN22EReRq\n4ICqrgh1LKWoItAJeEtVzwKO4r9dAJTL81wLuBYnCZ4MVCXvLZRyr7TOq1sSwV7glGzTTbzzyjwR\nicRJAhNV9Qvv7P0i0si7vBFwwDu/PHwOFwDXiMgOYDLO7aExQE0Rqegtk/24fMfsXX4SkFCaAZeA\nPcAeVV3qnZ6KkxjK83m+HNiuqvGqmg58gXPuy/N5znK85/WEz7dbEsFy4HRvi4NKOJVOM0Ic0wkT\nEQHeBzaq6ivZFs0AsloODMSpO8iaf4u39cF5QGK2S9AyQVUfUdUmqtoM5zzOU9V+wI9Ab2+x3Mec\n9Vn09pYvU7+cVXUfsFtEWnlnXQZsoByfZ5xbQueJSBXvv/OsYy635zmb4z2vc4ArRaSW90rqSu+8\nwIW6oqQUK2R6Ar8DW4HHQh1PCR1TV5zLxjXAKu/QE+fe6A/AZuB7oLa3vOC0ntoKrMVpkRHy4ziB\n478Y+MY73hxYBmwBPgeivPOjvdNbvMubhzruYh5rRyDWe66/AmqV9/MMjAJ+A9YBHwNR5e08A5Nw\n6kDSca78hhbnvAJDvMe+BRh8vHFYFxPGGONybrk1ZIwxpgCWCIwxxuUsERhjjMtZIjDGGJezRGCM\nMS5nicCYXEQkU0RWZRtKrLdaEWmWvadJY8JBxaKLGOM6yaraMdRBGFNa7IrAmACJyA4ReUlE1orI\nMhFp6Z3fTETmefuI/0FEmnrnNxCRL0VktXc437upCBF519vX/nciUjlkB2UMlgiMyU/lXLeG+mRb\nlqiq7YA3cHpBBRgLfKSq7YGJwOve+a8DP6tqB5y+gdZ7558OvKmqbYBDwPVBPh5jCmVPFhuTi4gc\nUdVq+czfAVyqqtu8nf3tU9U6InIQp//4dO/8OFWtKyLxQBNVTc22jWbAXHVeOoKIPAxEquozwT8y\nY/JnVwTGHB8tYPx4pGYbz8Tq6kyIWSIw5vj0yfZ3sXd8EU5PqAD9gF+84z8Ad4DvHcsnlVaQxhwP\n+yViTF6VRWRVtunZqprVhLSWiKzB+VXf1zvvXzhvD/s3zpvEBnvn3wO8IyJDcX7534HT06QxYcXq\nCIwJkLeOIEZVD4Y6FmNKkt0aMsYYl7MrAmOMcTm7IjDGGJezRGCMMS5nicAYY1zOEoExxricJQJj\njHG5/wdwyUldZB3IUQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zHeX9CfTExb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resumo da Rede\n",
        "history = model.fit(X,\n",
        "                   Y,\n",
        "                   epochs=1000,\n",
        "                   verbose=1,\n",
        "                   batch_size=250,\n",
        "                   validation_data=(X,Y))\n",
        "\n",
        "\n",
        "training_loss = history.history['loss']\n",
        "test_loss = history.history['val_loss']\n",
        "\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, test_loss, 'b-')\n",
        "plt.legend(['Training Loss', 'Test Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}